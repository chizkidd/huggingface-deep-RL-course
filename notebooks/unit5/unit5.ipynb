{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Unit 5: An Introduction to ML-Agents\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/thumbnail.png\" alt=\"Thumbnail\"/>\n\nIn this notebook, you'll learn about ML-Agents and train two agents:\n\n- **SnowballTarget**: Learn to shoot snowballs onto spawning targets\n- **Pyramids**: Press a button to spawn a pyramid, navigate to it, knock it over, and move to the gold brick at the top (uses curiosity)\n\nAfter training, you'll be able to **watch your agents playing directly in your browser**.\n\nüìÑ Course: https://huggingface.co/deep-rl-course/en/unit0/introduction#certification-process","metadata":{}},{"cell_type":"markdown","source":"‚¨áÔ∏è Here is what **you will achieve at the end of this unit** ‚¨áÔ∏è\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/pyramids.gif\" alt=\"Pyramids\"/>\n\n<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit7/snowballtarget.gif\" alt=\"SnowballTarget\"/>","metadata":{}},{"cell_type":"markdown","source":"### üéÆ Environments:\n\n- SnowballTarget\n- Pyramids\n\n### Before you start ‚úÖ\n\n- **Enable Internet** in Kaggle session settings\n- Add your HuggingFace write token as a Kaggle Secret named `HF_TOKEN`\n  - Kaggle sidebar ‚Üí Add-ons ‚Üí Secrets ‚Üí Add New Secret\n  - Get your token at: https://huggingface.co/settings/tokens","metadata":{}},{"cell_type":"markdown","source":"## Install ML-Agents üîΩ\n\nWe install ML-Agents in a Python 3.10 virtual environment to avoid compatibility issues with Kaggle's default Python 3.12.","metadata":{}},{"cell_type":"code","source":"%%capture\n!add-apt-repository ppa:deadsnakes/ppa -y\n!apt-get update -q\n!apt-get install -y python3.10 python3.10-venv python3.10-distutils -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T19:53:56.103168Z","iopub.execute_input":"2026-02-24T19:53:56.103505Z","iopub.status.idle":"2026-02-24T19:54:24.941752Z","shell.execute_reply.started":"2026-02-24T19:53:56.103476Z","shell.execute_reply":"2026-02-24T19:54:24.940673Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"%%capture\n# Create the environment\n!python3.10 -m venv /kaggle/working/mlagents-env\n!/kaggle/working/mlagents-env/bin/pip install --upgrade pip -q\n\n# Step A: Install PyTorch CPU first from the specific index\n!/kaggle/working/mlagents-env/bin/pip install torch --index-url https://download.pytorch.org/whl/cpu\n\n# Step B: Install mlagents and core dependencies from PyPI\n!/kaggle/working/mlagents-env/bin/pip install \\\n    \"mlagents==1.1.0\" \\\n    \"mlagents-envs==1.1.0\" \\\n    \"numpy==1.23.5\" \\\n    \"onnx==1.15.0\" \\\n    \"grpcio==1.48.2\" \\\n    \"protobuf==3.20.3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T19:55:21.946529Z","iopub.execute_input":"2026-02-24T19:55:21.946851Z","iopub.status.idle":"2026-02-24T19:56:13.977085Z","shell.execute_reply.started":"2026-02-24T19:55:21.946821Z","shell.execute_reply":"2026-02-24T19:56:13.976199Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Verify installation\n!/kaggle/working/mlagents-env/bin/mlagents-learn --help | head -50","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T19:57:08.219027Z","iopub.execute_input":"2026-02-24T19:57:08.219829Z","iopub.status.idle":"2026-02-24T19:57:10.483852Z","shell.execute_reply.started":"2026-02-24T19:57:08.219793Z","shell.execute_reply":"2026-02-24T19:57:10.483115Z"}},"outputs":[{"name":"stdout","text":"usage: mlagents-learn [-h] [--env ENV_PATH] [--resume] [--deterministic]\n                      [--force] [--run-id RUN_ID] [--initialize-from RUN_ID]\n                      [--seed SEED] [--inference] [--base-port BASE_PORT]\n                      [--num-envs NUM_ENVS] [--num-areas NUM_AREAS] [--debug]\n                      [--env-args ...]\n                      [--max-lifetime-restarts MAX_LIFETIME_RESTARTS]\n                      [--restarts-rate-limit-n RESTARTS_RATE_LIMIT_N]\n                      [--restarts-rate-limit-period-s RESTARTS_RATE_LIMIT_PERIOD_S]\n                      [--torch] [--tensorflow] [--results-dir RESULTS_DIR]\n                      [--timeout-wait TIMEOUT_WAIT] [--width WIDTH]\n                      [--height HEIGHT] [--quality-level QUALITY_LEVEL]\n                      [--time-scale TIME_SCALE]\n                      [--target-frame-rate TARGET_FRAME_RATE]\n                      [--capture-frame-rate CAPTURE_FRAME_RATE]\n                      [--no-graphics] [--no-graphics-monitor]\n                      [--torch-device DEVICE]\n                      [trainer_config_path]\n\npositional arguments:\n  trainer_config_path\n\noptions:\n  -h, --help            show this help message and exit\n  --env ENV_PATH        Path to the Unity executable to train (default: None)\n  --resume              Whether to resume training from a checkpoint. Specify\n                        a --run-id to use this option. If set, the training\n                        code loads an already trained model to initialize the\n                        neural network before resuming training. This option\n                        is only valid when the models exist, and have the same\n                        behavior names as the current agents in your scene.\n                        (default: False)\n  --deterministic       Whether to select actions deterministically in policy.\n                        `dist.mean` for continuous action space, and\n                        `dist.argmax` for deterministic action space (default:\n                        False)\n  --force               Whether to force-overwrite this run-id's existing\n                        summary and model data. (Without this flag, attempting\n                        to train a model with a run-id that has been used\n                        before will throw an error. (default: False)\n  --run-id RUN_ID       The identifier for the training run. This identifier\n                        is used to name the subdirectories in which the\n                        trained model and summary statistics are saved as well\n                        as the saved model itself. If you use TensorBoard to\n                        view the training statistics, always set a unique run-\n                        id for each training run. (The statistics for all runs\n                        with the same id are combined as if they were produced\n                        by a the same session.) (default: ppo)\n  --initialize-from RUN_ID\n                        Specify a previously saved run ID from which to\n                        initialize the model from. This can be used, for\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Download Environment Executables üîΩ","metadata":{}},{"cell_type":"code","source":"!mkdir -p ./training-envs-executables/SnowballTarget\n!mkdir -p ./training-envs-executables/Pyramids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T19:58:32.428888Z","iopub.execute_input":"2026-02-24T19:58:32.429473Z","iopub.status.idle":"2026-02-24T19:58:32.656265Z","shell.execute_reply.started":"2026-02-24T19:58:32.429438Z","shell.execute_reply":"2026-02-24T19:58:32.655002Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"%%capture\n!pip install huggingface_hub gdown -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T19:58:43.091754Z","iopub.execute_input":"2026-02-24T19:58:43.092349Z","iopub.status.idle":"2026-02-24T19:58:47.681900Z","shell.execute_reply.started":"2026-02-24T19:58:43.092309Z","shell.execute_reply":"2026-02-24T19:58:47.681117Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Download SnowballTarget\n!wget \"https://github.com/huggingface/Snowball-Target/raw/main/SnowballTarget.zip\" -O ./training-envs-executables/SnowballTarget.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T19:59:16.387106Z","iopub.execute_input":"2026-02-24T19:59:16.387456Z","iopub.status.idle":"2026-02-24T19:59:17.584339Z","shell.execute_reply.started":"2026-02-24T19:59:16.387424Z","shell.execute_reply":"2026-02-24T19:59:17.583618Z"}},"outputs":[{"name":"stdout","text":"--2026-02-24 19:59:16--  https://github.com/huggingface/Snowball-Target/raw/main/SnowballTarget.zip\nResolving github.com (github.com)... 140.82.112.4\nConnecting to github.com (github.com)|140.82.112.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://media.githubusercontent.com/media/huggingface/Snowball-Target/main/SnowballTarget.zip [following]\n--2026-02-24 19:59:16--  https://media.githubusercontent.com/media/huggingface/Snowball-Target/main/SnowballTarget.zip\nResolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\nConnecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 35134213 (34M) [application/zip]\nSaving to: ‚Äò./training-envs-executables/SnowballTarget.zip‚Äô\n\n./training-envs-exe 100%[===================>]  33.51M  73.3MB/s    in 0.5s    \n\n2026-02-24 19:59:17 (73.3 MB/s) - ‚Äò./training-envs-executables/SnowballTarget.zip‚Äô saved [35134213/35134213]\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"%%capture\n!unzip -d ./training-envs-executables/SnowballTarget/ ./training-envs-executables/SnowballTarget.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T19:59:20.434460Z","iopub.execute_input":"2026-02-24T19:59:20.434819Z","iopub.status.idle":"2026-02-24T19:59:21.539711Z","shell.execute_reply.started":"2026-02-24T19:59:20.434788Z","shell.execute_reply":"2026-02-24T19:59:21.538724Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"!chmod -R 755 ./training-envs-executables/SnowballTarget/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T19:59:26.450282Z","iopub.execute_input":"2026-02-24T19:59:26.451308Z","iopub.status.idle":"2026-02-24T19:59:26.569669Z","shell.execute_reply.started":"2026-02-24T19:59:26.451268Z","shell.execute_reply":"2026-02-24T19:59:26.568765Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Confirm the executable is present\n!ls -la ./training-envs-executables/SnowballTarget/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T19:59:29.770483Z","iopub.execute_input":"2026-02-24T19:59:29.771211Z","iopub.status.idle":"2026-02-24T19:59:29.889134Z","shell.execute_reply.started":"2026-02-24T19:59:29.771175Z","shell.execute_reply":"2026-02-24T19:59:29.888181Z"}},"outputs":[{"name":"stdout","text":"total 12\ndrwxr-xr-x 3 root root 4096 Feb 24 19:59 .\ndrwxr-xr-x 4 root root 4096 Feb 24 19:59 ..\ndrwxr-xr-x 4 root root 4096 Jan  8  2023 SnowballTarget\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!ls -R ./training-envs-executables/SnowballTarget/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T20:04:56.720693Z","iopub.execute_input":"2026-02-24T20:04:56.721429Z","iopub.status.idle":"2026-02-24T20:04:56.841205Z","shell.execute_reply.started":"2026-02-24T20:04:56.721389Z","shell.execute_reply":"2026-02-24T20:04:56.840603Z"}},"outputs":[{"name":"stdout","text":"./training-envs-executables/SnowballTarget/:\nSnowballTarget\n\n./training-envs-executables/SnowballTarget/SnowballTarget:\nSnowballTarget_BurstDebugInformation_DoNotShip\tSnowballTarget.x86_64\nSnowballTarget_Data\t\t\t\tUnityPlayer.so\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_BurstDebugInformation_DoNotShip:\nData\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_BurstDebugInformation_DoNotShip/Data:\nPlugins\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_BurstDebugInformation_DoNotShip/Data/Plugins:\nlib_burst_generated.txt\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_Data:\napp.info\t\t   Managed\t\t  RuntimeInitializeOnLoads.json\nboot.config\t\t   MonoBleedingEdge\t  ScriptingAssemblies.json\nglobalgamemanagers\t   Plugins\t\t  sharedassets0.assets\nglobalgamemanagers.assets  Resources\t\t  sharedassets0.assets.resS\nlevel0\t\t\t   resources.assets\t  StreamingAssets\nlevel0.resS\t\t   resources.assets.resS\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_Data/Managed:\nAssembly-CSharp.dll\nGoogle.Protobuf.dll\nGrpc.Core.dll\nMono.Security.dll\nmscorlib.dll\nnetstandard.dll\nNewtonsoft.Json.dll\nSystem.ComponentModel.Composition.dll\nSystem.Configuration.dll\nSystem.Core.dll\nSystem.Data.DataSetExtensions.dll\nSystem.Data.dll\nSystem.dll\nSystem.Drawing.dll\nSystem.EnterpriseServices.dll\nSystem.Interactive.Async.dll\nSystem.IO.Abstractions.dll\nSystem.IO.Abstractions.TestingHelpers.dll\nSystem.IO.Compression.dll\nSystem.IO.Compression.FileSystem.dll\nSystem.Net.Http.dll\nSystem.Numerics.dll\nSystem.Runtime.dll\nSystem.Runtime.Serialization.dll\nSystem.Security.dll\nSystem.ServiceModel.Internals.dll\nSystem.Transactions.dll\nSystem.Xml.dll\nSystem.Xml.Linq.dll\nUnity.Barracuda.BurstBLAS.dll\nUnity.Barracuda.dll\nUnity.Barracuda.ONNX.dll\nUnity.Burst.Cecil.dll\nUnity.Burst.Cecil.Mdb.dll\nUnity.Burst.Cecil.Pdb.dll\nUnity.Burst.Cecil.Rocks.dll\nUnity.Burst.dll\nUnity.Burst.Unsafe.dll\nUnityEngine.AccessibilityModule.dll\nUnityEngine.AIModule.dll\nUnityEngine.AndroidJNIModule.dll\nUnityEngine.AnimationModule.dll\nUnityEngine.AssetBundleModule.dll\nUnityEngine.AudioModule.dll\nUnityEngine.ClothModule.dll\nUnityEngine.ClusterInputModule.dll\nUnityEngine.ClusterRendererModule.dll\nUnityEngine.CoreModule.dll\nUnityEngine.CrashReportingModule.dll\nUnityEngine.DirectorModule.dll\nUnityEngine.dll\nUnityEngine.DSPGraphModule.dll\nUnityEngine.GameCenterModule.dll\nUnityEngine.GIModule.dll\nUnityEngine.GridModule.dll\nUnityEngine.HotReloadModule.dll\nUnityEngine.ImageConversionModule.dll\nUnityEngine.IMGUIModule.dll\nUnityEngine.InputLegacyModule.dll\nUnityEngine.InputModule.dll\nUnityEngine.JSONSerializeModule.dll\nUnityEngine.LocalizationModule.dll\nUnityEngine.ParticleSystemModule.dll\nUnityEngine.PerformanceReportingModule.dll\nUnityEngine.Physics2DModule.dll\nUnityEngine.PhysicsModule.dll\nUnityEngine.ProfilerModule.dll\nUnityEngine.RuntimeInitializeOnLoadManagerInitializerModule.dll\nUnityEngine.ScreenCaptureModule.dll\nUnityEngine.SharedInternalsModule.dll\nUnityEngine.SpriteMaskModule.dll\nUnityEngine.SpriteShapeModule.dll\nUnityEngine.StreamingModule.dll\nUnityEngine.SubstanceModule.dll\nUnityEngine.SubsystemsModule.dll\nUnityEngine.TerrainModule.dll\nUnityEngine.TerrainPhysicsModule.dll\nUnityEngine.TextCoreFontEngineModule.dll\nUnityEngine.TextCoreTextEngineModule.dll\nUnityEngine.TextRenderingModule.dll\nUnityEngine.TilemapModule.dll\nUnityEngine.TLSModule.dll\nUnityEngine.UI.dll\nUnityEngine.UIElementsModule.dll\nUnityEngine.UIElementsNativeModule.dll\nUnityEngine.UIModule.dll\nUnityEngine.UmbraModule.dll\nUnityEngine.UNETModule.dll\nUnityEngine.UnityAnalyticsCommonModule.dll\nUnityEngine.UnityAnalyticsModule.dll\nUnityEngine.UnityConnectModule.dll\nUnityEngine.UnityCurlModule.dll\nUnityEngine.UnityTestProtocolModule.dll\nUnityEngine.UnityWebRequestAssetBundleModule.dll\nUnityEngine.UnityWebRequestAudioModule.dll\nUnityEngine.UnityWebRequestModule.dll\nUnityEngine.UnityWebRequestTextureModule.dll\nUnityEngine.UnityWebRequestWWWModule.dll\nUnityEngine.VehiclesModule.dll\nUnityEngine.VFXModule.dll\nUnityEngine.VideoModule.dll\nUnityEngine.VirtualTexturingModule.dll\nUnityEngine.VRModule.dll\nUnityEngine.WindModule.dll\nUnityEngine.XRModule.dll\nUnity.Mathematics.dll\nUnity.ML-Agents.CommunicatorObjects.dll\nUnity.ML-Agents.dll\nUnity.ProGrids.dll\nUnity.Services.Core.Analytics.dll\nUnity.Services.Core.Configuration.dll\nUnity.Services.Core.Device.dll\nUnity.Services.Core.dll\nUnity.Services.Core.Environments.dll\nUnity.Services.Core.Environments.Internal.dll\nUnity.Services.Core.Internal.dll\nUnity.Services.Core.Networking.dll\nUnity.Services.Core.Registration.dll\nUnity.Services.Core.Scheduler.dll\nUnity.Services.Core.Telemetry.dll\nUnity.Services.Core.Threading.dll\nUnity.TextMeshPro.dll\nUnity.Timeline.dll\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_Data/MonoBleedingEdge:\netc  x86_64\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_Data/MonoBleedingEdge/etc:\nconfig\tmono\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_Data/MonoBleedingEdge/etc/mono:\n2.0  4.0  4.5  browscap.ini  config  mconfig\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_Data/MonoBleedingEdge/etc/mono/2.0:\nBrowsers\t\t       machine.config  web.config\nDefaultWsdlHelpGenerator.aspx  settings.map\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_Data/MonoBleedingEdge/etc/mono/2.0/Browsers:\nCompat.browser\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_Data/MonoBleedingEdge/etc/mono/4.0:\nBrowsers\t\t       machine.config  web.config\nDefaultWsdlHelpGenerator.aspx  settings.map\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_Data/MonoBleedingEdge/etc/mono/4.0/Browsers:\nCompat.browser\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_Data/MonoBleedingEdge/etc/mono/4.5:\nBrowsers\t\t       machine.config  web.config\nDefaultWsdlHelpGenerator.aspx  settings.map\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_Data/MonoBleedingEdge/etc/mono/4.5/Browsers:\nCompat.browser\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_Data/MonoBleedingEdge/etc/mono/mconfig:\nconfig.xml\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_Data/MonoBleedingEdge/x86_64:\nlibmonobdwgc-2.0.so  libmono-native.so\tlibMonoPosixHelper.so\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_Data/Plugins:\nlib_burst_generated.so\tlibgrpc_csharp_ext.x64.so\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_Data/Resources:\n unity_builtin_extra  'unity default resources'   UnityPlayer.png\n\n./training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget_Data/StreamingAssets:\nUnityServicesProjectConfiguration.json\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Download Pyramids\n!wget \"https://huggingface.co/spaces/unity/ML-Agents-Pyramids/resolve/main/Pyramids.zip\" -O ./training-envs-executables/Pyramids.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T20:07:28.003915Z","iopub.execute_input":"2026-02-24T20:07:28.004737Z","iopub.status.idle":"2026-02-24T20:07:41.531904Z","shell.execute_reply.started":"2026-02-24T20:07:28.004701Z","shell.execute_reply":"2026-02-24T20:07:41.531127Z"}},"outputs":[{"name":"stdout","text":"--2026-02-24 20:07:28--  https://huggingface.co/spaces/unity/ML-Agents-Pyramids/resolve/main/Pyramids.zip\nResolving huggingface.co (huggingface.co)... 3.170.185.25, 3.170.185.14, 3.170.185.35, ...\nConnecting to huggingface.co (huggingface.co)|3.170.185.25|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://us.gcp.cdn.hf.co/xet-bridge-us/62b2c0284ea3eff279c966ab/2f754b6bf0b817493a77fafe582b7dde47fa25a476d3f8e68a24fdd4efcaa282?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Pyramids.zip%3B+filename%3D%22Pyramids.zip%22%3B&response-content-type=application%2Fzip&Expires=1771967248&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzcxOTY3MjQ4fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjJiMmMwMjg0ZWEzZWZmMjc5Yzk2NmFiLzJmNzU0YjZiZjBiODE3NDkzYTc3ZmFmZTU4MmI3ZGRlNDdmYTI1YTQ3NmQzZjhlNjhhMjRmZGQ0ZWZjYWEyODJcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=HtsYW0ZL5VzC9TuIWETRaG3oAXBMtyJImFsvVh6aGDL9fYLhjp2-uyX%7E36HroY9V4MaTmNnBsmwlEEMkzZ27yK-NQHKmQH6WTXf92iLqJx7bkKrjKTShIymjlcep%7ELnCkK2StlggyHnLBsCqM7ATJuzkhSHGmn7FxCoCnqxgc0zRlhMCycEK2Wk8uiMAgM%7ELm979lP2xmZmvRJJ3Dstt1xRzClV6rQwFLRibvdAvnt91iowcxGmDBJS2t2mHGQTzmSNmAlFcb6FFOIROVNrj-G9b2zDUCC89TUsY3V2k5UHzDTS%7En6PGXY%7EnRL%7ELvpaaJPyUnducSlVYO%7EWgJiedfQ__&Key-Pair-Id=KJLH8B0YWU4Y8M [following]\n--2026-02-24 20:07:28--  https://us.gcp.cdn.hf.co/xet-bridge-us/62b2c0284ea3eff279c966ab/2f754b6bf0b817493a77fafe582b7dde47fa25a476d3f8e68a24fdd4efcaa282?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Pyramids.zip%3B+filename%3D%22Pyramids.zip%22%3B&response-content-type=application%2Fzip&Expires=1771967248&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzcxOTY3MjQ4fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjJiMmMwMjg0ZWEzZWZmMjc5Yzk2NmFiLzJmNzU0YjZiZjBiODE3NDkzYTc3ZmFmZTU4MmI3ZGRlNDdmYTI1YTQ3NmQzZjhlNjhhMjRmZGQ0ZWZjYWEyODJcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=HtsYW0ZL5VzC9TuIWETRaG3oAXBMtyJImFsvVh6aGDL9fYLhjp2-uyX%7E36HroY9V4MaTmNnBsmwlEEMkzZ27yK-NQHKmQH6WTXf92iLqJx7bkKrjKTShIymjlcep%7ELnCkK2StlggyHnLBsCqM7ATJuzkhSHGmn7FxCoCnqxgc0zRlhMCycEK2Wk8uiMAgM%7ELm979lP2xmZmvRJJ3Dstt1xRzClV6rQwFLRibvdAvnt91iowcxGmDBJS2t2mHGQTzmSNmAlFcb6FFOIROVNrj-G9b2zDUCC89TUsY3V2k5UHzDTS%7En6PGXY%7EnRL%7ELvpaaJPyUnducSlVYO%7EWgJiedfQ__&Key-Pair-Id=KJLH8B0YWU4Y8M\nResolving us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)... 35.209.178.129\nConnecting to us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)|35.209.178.129|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 42907187 (41M) [application/zip]\nSaving to: ‚Äò./training-envs-executables/Pyramids.zip‚Äô\n\n./training-envs-exe 100%[===================>]  40.92M  1.92MB/s    in 13s     \n\n2026-02-24 20:07:41 (3.10 MB/s) - ‚Äò./training-envs-executables/Pyramids.zip‚Äô saved [42907187/42907187]\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"%%capture\n!unzip -d ./training-envs-executables/Pyramids/ ./training-envs-executables/Pyramids.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T20:07:50.257708Z","iopub.execute_input":"2026-02-24T20:07:50.258384Z","iopub.status.idle":"2026-02-24T20:07:51.625057Z","shell.execute_reply.started":"2026-02-24T20:07:50.258350Z","shell.execute_reply":"2026-02-24T20:07:51.624099Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"!chmod -R 755 ./training-envs-executables/Pyramids/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T20:07:51.626651Z","iopub.execute_input":"2026-02-24T20:07:51.627272Z","iopub.status.idle":"2026-02-24T20:07:51.745870Z","shell.execute_reply.started":"2026-02-24T20:07:51.627241Z","shell.execute_reply":"2026-02-24T20:07:51.744801Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Confirm the executable is present\n!ls -la ./training-envs-executables/Pyramids/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T20:07:51.767355Z","iopub.execute_input":"2026-02-24T20:07:51.767990Z","iopub.status.idle":"2026-02-24T20:07:51.886211Z","shell.execute_reply.started":"2026-02-24T20:07:51.767958Z","shell.execute_reply":"2026-02-24T20:07:51.885490Z"}},"outputs":[{"name":"stdout","text":"total 12\ndrwxr-xr-x 3 root root 4096 Feb 24 20:07 .\ndrwxr-xr-x 4 root root 4096 Feb 24 20:07 ..\ndrwxr-xr-x 4 root root 4096 Jun 23  2022 Pyramids\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"!ls -R ./training-envs-executables/Pyramids/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T20:08:17.482419Z","iopub.execute_input":"2026-02-24T20:08:17.483376Z","iopub.status.idle":"2026-02-24T20:08:17.601813Z","shell.execute_reply.started":"2026-02-24T20:08:17.483331Z","shell.execute_reply":"2026-02-24T20:08:17.601125Z"}},"outputs":[{"name":"stdout","text":"./training-envs-executables/Pyramids/:\nPyramids\n\n./training-envs-executables/Pyramids/Pyramids:\nPyramids\t\t\t\t  Pyramids_Data\nPyramids_BurstDebugInformation_DoNotShip  UnityPlayer.so\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_BurstDebugInformation_DoNotShip:\nData\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_BurstDebugInformation_DoNotShip/Data:\nPlugins\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_BurstDebugInformation_DoNotShip/Data/Plugins:\nlib_burst_generated.txt\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_Data:\napp.info\t\t   Managed\t     resources.assets\nboot.config\t\t   ML-Agents\t     RuntimeInitializeOnLoads.json\nglobalgamemanagers\t   MonoBleedingEdge  ScriptingAssemblies.json\nglobalgamemanagers.assets  Plugins\t     sharedassets0.assets\nlevel0\t\t\t   Resources\t     sharedassets0.assets.resS\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_Data/Managed:\nAssembly-CSharp.dll\nAssembly-CSharp.pdb\nGoogle.Protobuf.dll\nGoogle.Protobuf.pdb\nGrpc.Core.dll\nMono.Security.dll\nmscorlib.dll\nnetstandard.dll\nNewtonsoft.Json.dll\nNewtonsoft.Json.pdb\nSystem.ComponentModel.Composition.dll\nSystem.Configuration.dll\nSystem.Core.dll\nSystem.Data.DataSetExtensions.dll\nSystem.Data.dll\nSystem.dll\nSystem.Drawing.dll\nSystem.EnterpriseServices.dll\nSystem.Interactive.Async.dll\nSystem.IO.Abstractions.dll\nSystem.IO.Abstractions.TestingHelpers.dll\nSystem.IO.Compression.dll\nSystem.IO.Compression.FileSystem.dll\nSystem.Net.Http.dll\nSystem.Numerics.dll\nSystem.Runtime.dll\nSystem.Runtime.Serialization.dll\nSystem.Security.dll\nSystem.ServiceModel.Internals.dll\nSystem.Transactions.dll\nSystem.Xml.dll\nSystem.Xml.Linq.dll\nUnity.Barracuda.BurstBLAS.dll\nUnity.Barracuda.BurstBLAS.pdb\nUnity.Barracuda.dll\nUnity.Barracuda.ONNX.dll\nUnity.Barracuda.ONNX.pdb\nUnity.Barracuda.pdb\nUnity.Burst.Cecil.dll\nUnity.Burst.Cecil.Mdb.dll\nUnity.Burst.Cecil.Pdb.dll\nUnity.Burst.Cecil.Rocks.dll\nUnity.Burst.dll\nUnity.Burst.pdb\nUnity.Burst.Unsafe.dll\nUnityEngine.AccessibilityModule.dll\nUnityEngine.AccessibilityModule.pdb\nUnityEngine.AIModule.dll\nUnityEngine.AIModule.pdb\nUnityEngine.AndroidJNIModule.dll\nUnityEngine.AndroidJNIModule.pdb\nUnityEngine.AnimationModule.dll\nUnityEngine.AnimationModule.pdb\nUnityEngine.AssetBundleModule.dll\nUnityEngine.AssetBundleModule.pdb\nUnityEngine.AudioModule.dll\nUnityEngine.AudioModule.pdb\nUnityEngine.ClothModule.dll\nUnityEngine.ClothModule.pdb\nUnityEngine.ClusterInputModule.dll\nUnityEngine.ClusterInputModule.pdb\nUnityEngine.ClusterRendererModule.dll\nUnityEngine.ClusterRendererModule.pdb\nUnityEngine.CoreModule.dll\nUnityEngine.CoreModule.pdb\nUnityEngine.CrashReportingModule.dll\nUnityEngine.CrashReportingModule.pdb\nUnityEngine.DirectorModule.dll\nUnityEngine.DirectorModule.pdb\nUnityEngine.dll\nUnityEngine.DSPGraphModule.dll\nUnityEngine.DSPGraphModule.pdb\nUnityEngine.GameCenterModule.dll\nUnityEngine.GameCenterModule.pdb\nUnityEngine.GIModule.dll\nUnityEngine.GIModule.pdb\nUnityEngine.GridModule.dll\nUnityEngine.GridModule.pdb\nUnityEngine.HotReloadModule.dll\nUnityEngine.HotReloadModule.pdb\nUnityEngine.ImageConversionModule.dll\nUnityEngine.ImageConversionModule.pdb\nUnityEngine.IMGUIModule.dll\nUnityEngine.IMGUIModule.pdb\nUnityEngine.InputLegacyModule.dll\nUnityEngine.InputLegacyModule.pdb\nUnityEngine.InputModule.dll\nUnityEngine.InputModule.pdb\nUnityEngine.JSONSerializeModule.dll\nUnityEngine.JSONSerializeModule.pdb\nUnityEngine.LocalizationModule.dll\nUnityEngine.LocalizationModule.pdb\nUnityEngine.ParticleSystemModule.dll\nUnityEngine.ParticleSystemModule.pdb\nUnityEngine.pdb\nUnityEngine.PerformanceReportingModule.dll\nUnityEngine.PerformanceReportingModule.pdb\nUnityEngine.Physics2DModule.dll\nUnityEngine.Physics2DModule.pdb\nUnityEngine.PhysicsModule.dll\nUnityEngine.PhysicsModule.pdb\nUnityEngine.ProfilerModule.dll\nUnityEngine.ProfilerModule.pdb\nUnityEngine.RuntimeInitializeOnLoadManagerInitializerModule.dll\nUnityEngine.RuntimeInitializeOnLoadManagerInitializerModule.pdb\nUnityEngine.ScreenCaptureModule.dll\nUnityEngine.ScreenCaptureModule.pdb\nUnityEngine.SharedInternalsModule.dll\nUnityEngine.SharedInternalsModule.pdb\nUnityEngine.SpriteMaskModule.dll\nUnityEngine.SpriteMaskModule.pdb\nUnityEngine.SpriteShapeModule.dll\nUnityEngine.SpriteShapeModule.pdb\nUnityEngine.StreamingModule.dll\nUnityEngine.StreamingModule.pdb\nUnityEngine.SubstanceModule.dll\nUnityEngine.SubstanceModule.pdb\nUnityEngine.SubsystemsModule.dll\nUnityEngine.SubsystemsModule.pdb\nUnityEngine.TerrainModule.dll\nUnityEngine.TerrainModule.pdb\nUnityEngine.TerrainPhysicsModule.dll\nUnityEngine.TerrainPhysicsModule.pdb\nUnityEngine.TextCoreFontEngineModule.dll\nUnityEngine.TextCoreFontEngineModule.pdb\nUnityEngine.TextCoreTextEngineModule.dll\nUnityEngine.TextCoreTextEngineModule.pdb\nUnityEngine.TextRenderingModule.dll\nUnityEngine.TextRenderingModule.pdb\nUnityEngine.TilemapModule.dll\nUnityEngine.TilemapModule.pdb\nUnityEngine.TLSModule.dll\nUnityEngine.TLSModule.pdb\nUnityEngine.UI.dll\nUnityEngine.UIElementsModule.dll\nUnityEngine.UIElementsModule.pdb\nUnityEngine.UIElementsNativeModule.dll\nUnityEngine.UIElementsNativeModule.pdb\nUnityEngine.UIModule.dll\nUnityEngine.UIModule.pdb\nUnityEngine.UI.pdb\nUnityEngine.UmbraModule.dll\nUnityEngine.UmbraModule.pdb\nUnityEngine.UNETModule.dll\nUnityEngine.UNETModule.pdb\nUnityEngine.UnityAnalyticsModule.dll\nUnityEngine.UnityAnalyticsModule.pdb\nUnityEngine.UnityConnectModule.dll\nUnityEngine.UnityConnectModule.pdb\nUnityEngine.UnityCurlModule.dll\nUnityEngine.UnityCurlModule.pdb\nUnityEngine.UnityTestProtocolModule.dll\nUnityEngine.UnityTestProtocolModule.pdb\nUnityEngine.UnityWebRequestAssetBundleModule.dll\nUnityEngine.UnityWebRequestAssetBundleModule.pdb\nUnityEngine.UnityWebRequestAudioModule.dll\nUnityEngine.UnityWebRequestAudioModule.pdb\nUnityEngine.UnityWebRequestModule.dll\nUnityEngine.UnityWebRequestModule.pdb\nUnityEngine.UnityWebRequestTextureModule.dll\nUnityEngine.UnityWebRequestTextureModule.pdb\nUnityEngine.UnityWebRequestWWWModule.dll\nUnityEngine.UnityWebRequestWWWModule.pdb\nUnityEngine.VehiclesModule.dll\nUnityEngine.VehiclesModule.pdb\nUnityEngine.VFXModule.dll\nUnityEngine.VFXModule.pdb\nUnityEngine.VideoModule.dll\nUnityEngine.VideoModule.pdb\nUnityEngine.VirtualTexturingModule.dll\nUnityEngine.VirtualTexturingModule.pdb\nUnityEngine.VRModule.dll\nUnityEngine.VRModule.pdb\nUnityEngine.WindModule.dll\nUnityEngine.WindModule.pdb\nUnityEngine.XRModule.dll\nUnityEngine.XRModule.pdb\nUnity.InputSystem.dll\nUnity.InputSystem.pdb\nUnity.Mathematics.dll\nUnity.Mathematics.pdb\nUnity.ML-Agents.CommunicatorObjects.dll\nUnity.ML-Agents.CommunicatorObjects.pdb\nUnity.ML-Agents.dll\nUnity.ML-Agents.Extensions.dll\nUnity.ML-Agents.Extensions.Input.dll\nUnity.ML-Agents.Extensions.Input.pdb\nUnity.ML-Agents.Extensions.pdb\nUnity.ML-Agents.pdb\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_Data/ML-Agents:\nTimers\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_Data/ML-Agents/Timers:\nPyramids_timers.json\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_Data/MonoBleedingEdge:\netc  x86_64\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_Data/MonoBleedingEdge/etc:\nconfig\tmono\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_Data/MonoBleedingEdge/etc/mono:\n2.0  4.0  4.5  browscap.ini  config  mconfig\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_Data/MonoBleedingEdge/etc/mono/2.0:\nBrowsers\t\t       machine.config  web.config\nDefaultWsdlHelpGenerator.aspx  settings.map\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_Data/MonoBleedingEdge/etc/mono/2.0/Browsers:\nCompat.browser\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_Data/MonoBleedingEdge/etc/mono/4.0:\nBrowsers\t\t       machine.config  web.config\nDefaultWsdlHelpGenerator.aspx  settings.map\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_Data/MonoBleedingEdge/etc/mono/4.0/Browsers:\nCompat.browser\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_Data/MonoBleedingEdge/etc/mono/4.5:\nBrowsers\t\t       machine.config  web.config\nDefaultWsdlHelpGenerator.aspx  settings.map\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_Data/MonoBleedingEdge/etc/mono/4.5/Browsers:\nCompat.browser\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_Data/MonoBleedingEdge/etc/mono/mconfig:\nconfig.xml\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_Data/MonoBleedingEdge/x86_64:\nlibmonobdwgc-2.0.so  libmono-native.so\tlibMonoPosixHelper.so\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_Data/Plugins:\nlib_burst_generated.so\tlibgrpc_csharp_ext.x64.so\n\n./training-envs-executables/Pyramids/Pyramids/Pyramids_Data/Resources:\n unity_builtin_extra  'unity default resources'   UnityPlayer.png\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## Part 1: SnowballTarget ‚ùÑÔ∏èüéØ\n\nTrain an agent to shoot snowballs at spawning targets.","metadata":{}},{"cell_type":"markdown","source":"### Create the SnowballTarget config file","metadata":{}},{"cell_type":"code","source":"import os\n\nsnowball_config = \"\"\"\nbehaviors:\n  SnowballTarget:\n    trainer_type: ppo\n    hyperparameters:\n      batch_size: 128\n      buffer_size: 2048\n      learning_rate: 0.0003\n      beta: 0.005\n      epsilon: 0.2\n      lambd: 0.95\n      num_epoch: 3\n      learning_rate_schedule: linear\n    network_settings:\n      normalize: false\n      hidden_units: 256\n      num_layers: 2\n      vis_encode_type: simple\n    reward_signals:\n      extrinsic:\n        gamma: 0.99\n        strength: 1.0\n    checkpoint_interval: 200000\n    keep_checkpoints: 5\n    max_steps: 1000000\n    time_horizon: 64\n    summary_freq: 10000\n\"\"\"\n\nos.makedirs(\"/kaggle/working/ml-agents/config/ppo\", exist_ok=True)\nwith open(\"/kaggle/working/ml-agents/config/ppo/SnowballTarget.yaml\", \"w\") as f:\n    f.write(snowball_config)\n\nprint(\"‚úÖ SnowballTarget config written to: /kaggle/working/ml-agents/config/ppo/SnowballTarget.yaml\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T20:09:58.729167Z","iopub.execute_input":"2026-02-24T20:09:58.729823Z","iopub.status.idle":"2026-02-24T20:09:58.736145Z","shell.execute_reply.started":"2026-02-24T20:09:58.729786Z","shell.execute_reply":"2026-02-24T20:09:58.735628Z"}},"outputs":[{"name":"stdout","text":"‚úÖ SnowballTarget config written to: /kaggle/working/ml-agents/config/ppo/SnowballTarget.yaml\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"### Train SnowballTarget agent\n\nTraining takes ~30‚Äì45 minutes. The agent learns to aim and shoot snowballs at targets.","metadata":{}},{"cell_type":"code","source":"!find /kaggle/working/ -name \"SnowballTarget.yaml\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T20:12:42.863689Z","iopub.execute_input":"2026-02-24T20:12:42.864643Z","iopub.status.idle":"2026-02-24T20:12:43.152713Z","shell.execute_reply.started":"2026-02-24T20:12:42.864605Z","shell.execute_reply":"2026-02-24T20:12:43.151810Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/ml-agents/config/ppo/SnowballTarget.yaml\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"!/kaggle/working/mlagents-env/bin/mlagents-learn \\\n    /kaggle/working/ml-agents/config/ppo/SnowballTarget.yaml \\\n    --env=/kaggle/working/training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget.x86_64 \\\n    --run-id=\"SnowballTarget1\" \\\n    --no-graphics \\\n    --force","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T20:17:47.053626Z","iopub.execute_input":"2026-02-24T20:17:47.054315Z","iopub.status.idle":"2026-02-24T20:23:50.750063Z","shell.execute_reply.started":"2026-02-24T20:17:47.054273Z","shell.execute_reply":"2026-02-24T20:23:50.749150Z"}},"outputs":[{"name":"stdout","text":"\n            ‚îê  ‚ïñ\n        ‚ïì‚ïñ‚ï¨‚îÇ‚ï°  ‚îÇ‚îÇ‚ï¨‚ïñ‚ïñ\n    ‚ïì‚ïñ‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚îò  ‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚ï¨‚ïñ\n ‚ïñ‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚ï¨‚ïú        ‚ïô‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚ïñ‚ïñ                               ‚ïó‚ïó‚ïó\n ‚ï¨‚ï¨‚ï¨‚ï¨‚ïñ‚îÇ‚îÇ‚ï¶‚ïñ        ‚ïñ‚ï¨‚îÇ‚îÇ‚ïó‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£             ‚ïú‚ïú‚ïú  ‚ïü‚ï£‚ï£\n ‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ïñ‚îÇ‚ï¨‚ïñ‚ïñ‚ïì‚ï¨‚ï™‚îÇ‚ïì‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£ ‚ïí‚ï£‚ï£‚ïñ‚ïó‚ï£‚ï£‚ï£‚ïó   ‚ï£‚ï£‚ï£ ‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£ ‚ïü‚ï£‚ï£‚ïñ   ‚ï£‚ï£‚ï£\n ‚ï¨‚ï¨‚ï¨‚ï¨‚îê  ‚ïô‚ï¨‚ï¨‚ï¨‚ï¨‚îÇ‚ïì‚ï£‚ï£‚ï£‚ïù‚ïú  ‚ï´‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£ ‚ïü‚ï£‚ï£‚ï£‚ïô ‚ïô‚ï£‚ï£‚ï£  ‚ï£‚ï£‚ï£ ‚ïô‚ïü‚ï£‚ï£‚ïú‚ïô  ‚ï´‚ï£‚ï£  ‚ïü‚ï£‚ï£\n ‚ï¨‚ï¨‚ï¨‚ï¨‚îê     ‚ïô‚ï¨‚ï¨‚ï£‚ï£      ‚ï´‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£ ‚ïü‚ï£‚ï£‚ï¨   ‚ï£‚ï£‚ï£  ‚ï£‚ï£‚ï£  ‚ïü‚ï£‚ï£     ‚ï£‚ï£‚ï£‚îå‚ï£‚ï£‚ïú\n ‚ï¨‚ï¨‚ï¨‚ïú       ‚ï¨‚ï¨‚ï£‚ï£      ‚ïô‚ïù‚ï£‚ï£‚ï¨      ‚ïô‚ï£‚ï£‚ï£‚ïó‚ïñ‚ïì‚ïó‚ï£‚ï£‚ï£‚ïú ‚ïü‚ï£‚ï£‚ï¨   ‚ï£‚ï£‚ï£  ‚ï£‚ï£‚ï£  ‚ïü‚ï£‚ï£‚ï¶‚ïì    ‚ï£‚ï£‚ï£‚ï£‚ï£\n ‚ïô   ‚ïì‚ï¶‚ïñ    ‚ï¨‚ï¨‚ï£‚ï£   ‚ïì‚ïó‚ïó‚ïñ            ‚ïô‚ïù‚ï£‚ï£‚ï£‚ï£‚ïù‚ïú   ‚ïò‚ïù‚ïù‚ïú   ‚ïù‚ïù‚ïù  ‚ïù‚ïù‚ïù   ‚ïô‚ï£‚ï£‚ï£    ‚ïü‚ï£‚ï£‚ï£\n   ‚ï©‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¶‚ï¶‚ï¨‚ï¨‚ï£‚ï£‚ïó‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ïù                                             ‚ï´‚ï£‚ï£‚ï£‚ï£\n      ‚ïô‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ïù‚ïú\n          ‚ïô‚ï¨‚ï¨‚ï¨‚ï£‚ï£‚ï£‚ïú\n             ‚ïô\n        \n Version information:\n  ml-agents: 1.1.0,\n  ml-agents-envs: 1.1.0,\n  Communicator API: 1.5.0,\n  PyTorch: 2.10.0+cpu\n[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n[INFO] Connected new brain: SnowballTarget?team=0\n[INFO] Hyperparameters for behavior name SnowballTarget: \n\ttrainer_type:\tppo\n\thyperparameters:\t\n\t  batch_size:\t128\n\t  buffer_size:\t2048\n\t  learning_rate:\t0.0003\n\t  beta:\t0.005\n\t  epsilon:\t0.2\n\t  lambd:\t0.95\n\t  num_epoch:\t3\n\t  shared_critic:\tFalse\n\t  learning_rate_schedule:\tlinear\n\t  beta_schedule:\tlinear\n\t  epsilon_schedule:\tlinear\n\tcheckpoint_interval:\t200000\n\tnetwork_settings:\t\n\t  normalize:\tFalse\n\t  hidden_units:\t256\n\t  num_layers:\t2\n\t  vis_encode_type:\tsimple\n\t  memory:\tNone\n\t  goal_conditioning_type:\thyper\n\t  deterministic:\tFalse\n\treward_signals:\t\n\t  extrinsic:\t\n\t    gamma:\t0.99\n\t    strength:\t1.0\n\t    network_settings:\t\n\t      normalize:\tFalse\n\t      hidden_units:\t128\n\t      num_layers:\t2\n\t      vis_encode_type:\tsimple\n\t      memory:\tNone\n\t      goal_conditioning_type:\thyper\n\t      deterministic:\tFalse\n\tinit_path:\tNone\n\tkeep_checkpoints:\t5\n\teven_checkpoints:\tFalse\n\tmax_steps:\t1000000\n\ttime_horizon:\t64\n\tsummary_freq:\t10000\n\tthreaded:\tFalse\n\tself_play:\tNone\n\tbehavioral_cloning:\tNone\n[INFO] SnowballTarget. Step: 10000. Time Elapsed: 19.001 s. Mean Reward: 3.795. Std of Reward: 1.995. Training.\n[INFO] SnowballTarget. Step: 20000. Time Elapsed: 37.908 s. Mean Reward: 6.691. Std of Reward: 2.879. Training.\n[INFO] SnowballTarget. Step: 30000. Time Elapsed: 55.105 s. Mean Reward: 8.205. Std of Reward: 2.710. Training.\n[INFO] SnowballTarget. Step: 40000. Time Elapsed: 73.790 s. Mean Reward: 12.782. Std of Reward: 2.896. Training.\n[INFO] SnowballTarget. Step: 50000. Time Elapsed: 91.887 s. Mean Reward: 14.886. Std of Reward: 2.414. Training.\n[INFO] SnowballTarget. Step: 60000. Time Elapsed: 109.500 s. Mean Reward: 15.618. Std of Reward: 2.370. Training.\n[INFO] SnowballTarget. Step: 70000. Time Elapsed: 126.932 s. Mean Reward: 18.318. Std of Reward: 2.530. Training.\n[INFO] SnowballTarget. Step: 80000. Time Elapsed: 145.023 s. Mean Reward: 20.745. Std of Reward: 2.414. Training.\n[INFO] SnowballTarget. Step: 90000. Time Elapsed: 161.220 s. Mean Reward: 23.409. Std of Reward: 2.026. Training.\n[INFO] SnowballTarget. Step: 100000. Time Elapsed: 180.526 s. Mean Reward: 23.927. Std of Reward: 2.350. Training.\n[INFO] SnowballTarget. Step: 110000. Time Elapsed: 198.283 s. Mean Reward: 24.204. Std of Reward: 2.320. Training.\n[INFO] SnowballTarget. Step: 120000. Time Elapsed: 215.972 s. Mean Reward: 23.311. Std of Reward: 2.648. Training.\n[INFO] SnowballTarget. Step: 130000. Time Elapsed: 235.264 s. Mean Reward: 24.018. Std of Reward: 2.268. Training.\n[INFO] SnowballTarget. Step: 140000. Time Elapsed: 252.434 s. Mean Reward: 25.091. Std of Reward: 2.193. Training.\n[INFO] SnowballTarget. Step: 150000. Time Elapsed: 271.206 s. Mean Reward: 24.673. Std of Reward: 2.442. Training.\n[INFO] SnowballTarget. Step: 160000. Time Elapsed: 289.138 s. Mean Reward: 24.727. Std of Reward: 2.425. Training.\n[INFO] SnowballTarget. Step: 170000. Time Elapsed: 307.672 s. Mean Reward: 24.727. Std of Reward: 2.347. Training.\n[INFO] SnowballTarget. Step: 180000. Time Elapsed: 325.413 s. Mean Reward: 22.364. Std of Reward: 3.966. Training.\n[INFO] SnowballTarget. Step: 190000. Time Elapsed: 343.961 s. Mean Reward: 23.764. Std of Reward: 3.406. Training.\n[INFO] SnowballTarget. Step: 200000. Time Elapsed: 360.892 s. Mean Reward: 22.909. Std of Reward: 3.168. Training.\nTraceback (most recent call last):\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/trainer_controller.py\", line 175, in start_learning\n    n_steps = self.advance(env_manager)\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents_envs/timers.py\", line 305, in wrapped\n    return func(*args, **kwargs)\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/trainer_controller.py\", line 250, in advance\n    trainer.advance()\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/trainer/rl_trainer.py\", line 293, in advance\n    self._process_trajectory(t)\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/ppo/trainer.py\", line 74, in _process_trajectory\n    super()._process_trajectory(trajectory)\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/trainer/rl_trainer.py\", line 224, in _process_trajectory\n    self._maybe_save_model(self.get_step + len(trajectory.steps))\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/trainer/rl_trainer.py\", line 264, in _maybe_save_model\n    self._checkpoint()\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents_envs/timers.py\", line 305, in wrapped\n    return func(*args, **kwargs)\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/trainer/rl_trainer.py\", line 144, in _checkpoint\n    export_path, auxillary_paths = self.model_saver.save_checkpoint(\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/model_saver/torch_model_saver.py\", line 60, in save_checkpoint\n    self.export(checkpoint_path, behavior_name)\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/model_saver/torch_model_saver.py\", line 65, in export\n    self.exporter.export_policy_model(output_filepath)\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/torch_entities/model_serialization.py\", line 164, in export_policy_model\n    torch.onnx.export(\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/torch/onnx/__init__.py\", line 282, in export\n    from torch.onnx._internal.exporter import _compat\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_compat.py\", line 16, in <module>\n    from torch.onnx._internal.exporter import (\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_core.py\", line 19, in <module>\n    import onnxscript\nModuleNotFoundError: No module named 'onnxscript'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/kaggle/working/mlagents-env/bin/mlagents-learn\", line 6, in <module>\n    sys.exit(main())\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/learn.py\", line 270, in main\n    run_cli(parse_command_line())\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/learn.py\", line 266, in run_cli\n    run_training(run_seed, options, num_areas)\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/learn.py\", line 138, in run_training\n    tc.start_learning(env_manager)\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents_envs/timers.py\", line 305, in wrapped\n    return func(*args, **kwargs)\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/trainer_controller.py\", line 200, in start_learning\n    self._save_models()\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents_envs/timers.py\", line 305, in wrapped\n    return func(*args, **kwargs)\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/trainer_controller.py\", line 80, in _save_models\n    self.trainers[brain_name].save_model()\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/trainer/rl_trainer.py\", line 172, in save_model\n    model_checkpoint = self._checkpoint()\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents_envs/timers.py\", line 305, in wrapped\n    return func(*args, **kwargs)\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/trainer/rl_trainer.py\", line 144, in _checkpoint\n    export_path, auxillary_paths = self.model_saver.save_checkpoint(\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/model_saver/torch_model_saver.py\", line 60, in save_checkpoint\n    self.export(checkpoint_path, behavior_name)\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/model_saver/torch_model_saver.py\", line 65, in export\n    self.exporter.export_policy_model(output_filepath)\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/torch_entities/model_serialization.py\", line 164, in export_policy_model\n    torch.onnx.export(\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/torch/onnx/__init__.py\", line 282, in export\n    from torch.onnx._internal.exporter import _compat\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_compat.py\", line 16, in <module>\n    from torch.onnx._internal.exporter import (\n  File \"/kaggle/working/mlagents-env/lib/python3.10/site-packages/torch/onnx/_internal/exporter/_core.py\", line 19, in <module>\n    import onnxscript\nModuleNotFoundError: No module named 'onnxscript'\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"!/kaggle/working/mlagents-env/bin/pip install \"torch==2.0.1\" --index-url https://download.pytorch.org/whl/cpu --force-reinstall\n!/kaggle/working/mlagents-env/bin/pip install onnxscript onnx==1.15.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T20:35:51.403661Z","iopub.execute_input":"2026-02-24T20:35:51.404463Z","iopub.status.idle":"2026-02-24T20:36:14.131954Z","shell.execute_reply.started":"2026-02-24T20:35:51.404406Z","shell.execute_reply":"2026-02-24T20:36:14.131216Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Ignoring invalid distribution -orch (/kaggle/working/mlagents-env/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cpu\nCollecting torch==2.0.1\n  Using cached https://download.pytorch.org/whl/cpu/torch-2.0.1%2Bcpu-cp310-cp310-linux_x86_64.whl (195.4 MB)\nCollecting filelock (from torch==2.0.1)\n  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\nCollecting typing-extensions (from torch==2.0.1)\n  Using cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting sympy (from torch==2.0.1)\n  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nCollecting networkx (from torch==2.0.1)\n  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\nCollecting jinja2 (from torch==2.0.1)\n  Using cached https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\nCollecting MarkupSafe>=2.0 (from jinja2->torch==2.0.1)\n  Using cached https://download.pytorch.org/whl/MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.0.1)\n  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\nUsing cached filelock-3.20.0-py3-none-any.whl (16 kB)\nUsing cached https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)\nUsing cached https://download.pytorch.org/whl/MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\nUsing cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\nUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\nUsing cached mpmath-1.3.0-py3-none-any.whl (536 kB)\nUsing cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n\u001b[33mWARNING: Ignoring invalid distribution -orch (/kaggle/working/mlagents-env/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: mpmath, typing-extensions, sympy, networkx, MarkupSafe, filelock, jinja2, torch\n\u001b[2K  Attempting uninstall: mpmath\n\u001b[2K    Found existing installation: mpmath 1.3.0\n\u001b[2K    Uninstalling mpmath-1.3.0:\n\u001b[2K      Successfully uninstalled mpmath-1.3.0\n\u001b[2K  Attempting uninstall: typing-extensions‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0/8\u001b[0m [mpmath]\n\u001b[2K    Found existing installation: typing_extensions 4.15.0\u001b[0m [mpmath]\n\u001b[2K    Uninstalling typing_extensions-4.15.0:‚îÅ‚îÅ\u001b[0m \u001b[32m0/8\u001b[0m [mpmath]\n\u001b[2K      Successfully uninstalled typing_extensions-4.15.0‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/8\u001b[0m [typing-extensions]\n\u001b[2K  Attempting uninstall: sympy‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/8\u001b[0m [typing-extensions]\n\u001b[2K    Found existing installation: sympy 1.14.0‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1/8\u001b[0m [typing-extensions]\n\u001b[2K    Uninstalling sympy-1.14.0:0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/8\u001b[0m [sympy]ensions]\n\u001b[2K      Successfully uninstalled sympy-1.14.0‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/8\u001b[0m [sympy]\n\u001b[2K  Attempting uninstall: networkx\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/8\u001b[0m [sympy]\n\u001b[2K    Found existing installation: networkx 3.4.2‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/8\u001b[0m [sympy]\n\u001b[2K    Uninstalling networkx-3.4.2:‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/8\u001b[0m [networkx]\n\u001b[2K      Successfully uninstalled networkx-3.4.2‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/8\u001b[0m [networkx]\n\u001b[2K  Attempting uninstall: MarkupSafe[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/8\u001b[0m [networkx]\n\u001b[2K    Found existing installation: MarkupSafe 3.0.2‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/8\u001b[0m [networkx]\n\u001b[2K    Uninstalling MarkupSafe-3.0.2:[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/8\u001b[0m [networkx]\n\u001b[2K      Successfully uninstalled MarkupSafe-3.0.2‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/8\u001b[0m [networkx]\n\u001b[2K  Attempting uninstall: filelockm\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/8\u001b[0m [networkx]\n\u001b[2K    Found existing installation: filelock 3.20.0‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/8\u001b[0m [networkx]\n\u001b[2K    Uninstalling filelock-3.20.0:\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5/8\u001b[0m [filelock]\n\u001b[2K      Successfully uninstalled filelock-3.20.00m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5/8\u001b[0m [filelock]\n\u001b[2K  Attempting uninstall: jinja2[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5/8\u001b[0m [filelock]\n\u001b[2K    Found existing installation: Jinja2 3.1.690m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5/8\u001b[0m [filelock]\n\u001b[2K    Uninstalling Jinja2-3.1.6:[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5/8\u001b[0m [filelock]\n\u001b[2K      Successfully uninstalled Jinja2-3.1.6\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5/8\u001b[0m [filelock]\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8/8\u001b[0m [torch]32m7/8\u001b[0m [torch]\n\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nmlagents 1.1.0 requires torch>=2.1.1, but you have torch 2.0.1+cpu which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/kaggle/working/mlagents-env/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n\u001b[0mSuccessfully installed MarkupSafe-3.0.2 filelock-3.20.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 sympy-1.14.0 torch-2.0.1+cpu typing-extensions-4.15.0\n\u001b[33mWARNING: Ignoring invalid distribution -orch (/kaggle/working/mlagents-env/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n\u001b[0mCollecting onnxscript\n  Using cached onnxscript-0.6.2-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: onnx==1.15.0 in ./mlagents-env/lib/python3.10/site-packages (1.15.0)\nRequirement already satisfied: numpy in ./mlagents-env/lib/python3.10/site-packages (from onnx==1.15.0) (1.23.5)\nRequirement already satisfied: protobuf>=3.20.2 in ./mlagents-env/lib/python3.10/site-packages (from onnx==1.15.0) (3.20.3)\nCollecting ml_dtypes (from onnxscript)\n  Using cached ml_dtypes-0.5.4-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\nCollecting onnx_ir<2,>=0.1.15 (from onnxscript)\n  Using cached onnx_ir-0.2.0-py3-none-any.whl.metadata (3.3 kB)\nINFO: pip is looking at multiple versions of onnxscript to determine which version is compatible with other requirements. This could take a while.\nCollecting onnxscript\n  Using cached onnxscript-0.6.1-py3-none-any.whl.metadata (13 kB)\n  Using cached onnxscript-0.6.0-py3-none-any.whl.metadata (13 kB)\n  Using cached onnxscript-0.5.7-py3-none-any.whl.metadata (13 kB)\n  Using cached onnxscript-0.5.6-py3-none-any.whl.metadata (13 kB)\n  Using cached onnxscript-0.5.4-py3-none-any.whl.metadata (13 kB)\n  Using cached onnxscript-0.5.3-py3-none-any.whl.metadata (13 kB)\n  Using cached onnxscript-0.5.2-py3-none-any.whl.metadata (13 kB)\nINFO: pip is still looking at multiple versions of onnxscript to determine which version is compatible with other requirements. This could take a while.\n  Using cached onnxscript-0.5.1-py3-none-any.whl.metadata (13 kB)\n  Using cached onnxscript-0.5.0-py3-none-any.whl.metadata (13 kB)\n  Using cached onnxscript-0.4.0-py3-none-any.whl.metadata (13 kB)\n  Using cached onnxscript-0.3.2-py3-none-any.whl.metadata (13 kB)\n  Using cached onnxscript-0.3.1-py3-none-any.whl.metadata (13 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Using cached onnxscript-0.3.0-py3-none-any.whl.metadata (14 kB)\n  Using cached onnxscript-0.2.7-py3-none-any.whl.metadata (15 kB)\n  Using cached onnxscript-0.2.6-py3-none-any.whl.metadata (15 kB)\n  Using cached onnxscript-0.2.5-py3-none-any.whl.metadata (15 kB)\n  Using cached onnxscript-0.2.4-py3-none-any.whl.metadata (15 kB)\n  Using cached onnxscript-0.2.3-py3-none-any.whl.metadata (15 kB)\n  Using cached onnxscript-0.2.2-py3-none-any.whl.metadata (15 kB)\n  Using cached onnxscript-0.2.1-py3-none-any.whl.metadata (15 kB)\n  Using cached onnxscript-0.2.0-py3-none-any.whl.metadata (15 kB)\n  Using cached onnxscript-0.1.0-py3-none-any.whl.metadata (15 kB)\nCollecting onnx==1.15.0\n  Using cached onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n\u001b[31mERROR: Cannot install onnx==1.15.0, onnxscript==0.1.0, onnxscript==0.2.0, onnxscript==0.2.1, onnxscript==0.2.2, onnxscript==0.2.3, onnxscript==0.2.4, onnxscript==0.2.5, onnxscript==0.2.6, onnxscript==0.2.7, onnxscript==0.3.0, onnxscript==0.3.1, onnxscript==0.3.2, onnxscript==0.4.0, onnxscript==0.5.0, onnxscript==0.5.1, onnxscript==0.5.2, onnxscript==0.5.3, onnxscript==0.5.4, onnxscript==0.5.6, onnxscript==0.5.7, onnxscript==0.6.0, onnxscript==0.6.1 and onnxscript==0.6.2 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n\u001b[0m\nThe conflict is caused by:\n    The user requested onnx==1.15.0\n    onnxscript 0.6.2 depends on onnx>=1.17\n    onnxscript 0.6.1 depends on onnx>=1.17\n    onnxscript 0.6.0 depends on onnx>=1.17\n    onnxscript 0.5.7 depends on onnx>=1.16\n    onnxscript 0.5.6 depends on onnx>=1.16\n    onnxscript 0.5.4 depends on onnx>=1.16\n    onnxscript 0.5.3 depends on onnx>=1.16\n    onnxscript 0.5.2 depends on onnx>=1.16\n    onnxscript 0.5.1 depends on onnx>=1.16\n    onnxscript 0.5.0 depends on onnx>=1.16\n    onnxscript 0.4.0 depends on onnx>=1.16\n    onnxscript 0.3.2 depends on onnx>=1.16\n    onnxscript 0.3.1 depends on onnx>=1.16\n    onnxscript 0.3.0 depends on onnx>=1.16\n    onnxscript 0.2.7 depends on onnx>=1.16\n    onnxscript 0.2.6 depends on onnx>=1.16\n    onnxscript 0.2.5 depends on onnx>=1.16\n    onnxscript 0.2.4 depends on onnx>=1.16\n    onnxscript 0.2.3 depends on onnx>=1.16\n    onnxscript 0.2.2 depends on onnx>=1.16\n    onnxscript 0.2.1 depends on onnx>=1.16\n    onnxscript 0.2.0 depends on onnx>=1.16\n    onnxscript 0.1.0 depends on onnx>=1.16\n\nAdditionally, some packages in these conflicts have no matching distributions available for your environment:\n    onnx\n\nTo fix this you could try to:\n1. loosen the range of package versions you've specified\n2. remove package versions to allow pip to attempt to solve the dependency conflict\n\n\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"!/kaggle/working/mlagents-env/bin/mlagents-learn \\\n    /kaggle/working/ml-agents/config/ppo/SnowballTarget.yaml \\\n    --env=/kaggle/working/training-envs-executables/SnowballTarget/SnowballTarget/SnowballTarget.x86_64 \\\n    --run-id=\"SnowballTarget1\" \\\n    --no-graphics \\\n    --resume","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T20:38:13.689641Z","iopub.execute_input":"2026-02-24T20:38:13.690450Z","iopub.status.idle":"2026-02-24T21:02:25.936278Z","shell.execute_reply.started":"2026-02-24T20:38:13.690415Z","shell.execute_reply":"2026-02-24T21:02:25.935609Z"}},"outputs":[{"name":"stdout","text":"\n            ‚îê  ‚ïñ\n        ‚ïì‚ïñ‚ï¨‚îÇ‚ï°  ‚îÇ‚îÇ‚ï¨‚ïñ‚ïñ\n    ‚ïì‚ïñ‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚îò  ‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚ï¨‚ïñ\n ‚ïñ‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚ï¨‚ïú        ‚ïô‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚ïñ‚ïñ                               ‚ïó‚ïó‚ïó\n ‚ï¨‚ï¨‚ï¨‚ï¨‚ïñ‚îÇ‚îÇ‚ï¶‚ïñ        ‚ïñ‚ï¨‚îÇ‚îÇ‚ïó‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£             ‚ïú‚ïú‚ïú  ‚ïü‚ï£‚ï£\n ‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ïñ‚îÇ‚ï¨‚ïñ‚ïñ‚ïì‚ï¨‚ï™‚îÇ‚ïì‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£ ‚ïí‚ï£‚ï£‚ïñ‚ïó‚ï£‚ï£‚ï£‚ïó   ‚ï£‚ï£‚ï£ ‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£ ‚ïü‚ï£‚ï£‚ïñ   ‚ï£‚ï£‚ï£\n ‚ï¨‚ï¨‚ï¨‚ï¨‚îê  ‚ïô‚ï¨‚ï¨‚ï¨‚ï¨‚îÇ‚ïì‚ï£‚ï£‚ï£‚ïù‚ïú  ‚ï´‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£ ‚ïü‚ï£‚ï£‚ï£‚ïô ‚ïô‚ï£‚ï£‚ï£  ‚ï£‚ï£‚ï£ ‚ïô‚ïü‚ï£‚ï£‚ïú‚ïô  ‚ï´‚ï£‚ï£  ‚ïü‚ï£‚ï£\n ‚ï¨‚ï¨‚ï¨‚ï¨‚îê     ‚ïô‚ï¨‚ï¨‚ï£‚ï£      ‚ï´‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£ ‚ïü‚ï£‚ï£‚ï¨   ‚ï£‚ï£‚ï£  ‚ï£‚ï£‚ï£  ‚ïü‚ï£‚ï£     ‚ï£‚ï£‚ï£‚îå‚ï£‚ï£‚ïú\n ‚ï¨‚ï¨‚ï¨‚ïú       ‚ï¨‚ï¨‚ï£‚ï£      ‚ïô‚ïù‚ï£‚ï£‚ï¨      ‚ïô‚ï£‚ï£‚ï£‚ïó‚ïñ‚ïì‚ïó‚ï£‚ï£‚ï£‚ïú ‚ïü‚ï£‚ï£‚ï¨   ‚ï£‚ï£‚ï£  ‚ï£‚ï£‚ï£  ‚ïü‚ï£‚ï£‚ï¶‚ïì    ‚ï£‚ï£‚ï£‚ï£‚ï£\n ‚ïô   ‚ïì‚ï¶‚ïñ    ‚ï¨‚ï¨‚ï£‚ï£   ‚ïì‚ïó‚ïó‚ïñ            ‚ïô‚ïù‚ï£‚ï£‚ï£‚ï£‚ïù‚ïú   ‚ïò‚ïù‚ïù‚ïú   ‚ïù‚ïù‚ïù  ‚ïù‚ïù‚ïù   ‚ïô‚ï£‚ï£‚ï£    ‚ïü‚ï£‚ï£‚ï£\n   ‚ï©‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¶‚ï¶‚ï¨‚ï¨‚ï£‚ï£‚ïó‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ïù                                             ‚ï´‚ï£‚ï£‚ï£‚ï£\n      ‚ïô‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ïù‚ïú\n          ‚ïô‚ï¨‚ï¨‚ï¨‚ï£‚ï£‚ï£‚ïú\n             ‚ïô\n        \n Version information:\n  ml-agents: 1.1.0,\n  ml-agents-envs: 1.1.0,\n  Communicator API: 1.5.0,\n  PyTorch: 2.0.1+cpu\n[WARNING] PyTorch checkpoint was saved with a different version of PyTorch. Model may not resume properly.\n[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n[INFO] Connected new brain: SnowballTarget?team=0\n[INFO] Hyperparameters for behavior name SnowballTarget: \n\ttrainer_type:\tppo\n\thyperparameters:\t\n\t  batch_size:\t128\n\t  buffer_size:\t2048\n\t  learning_rate:\t0.0003\n\t  beta:\t0.005\n\t  epsilon:\t0.2\n\t  lambd:\t0.95\n\t  num_epoch:\t3\n\t  shared_critic:\tFalse\n\t  learning_rate_schedule:\tlinear\n\t  beta_schedule:\tlinear\n\t  epsilon_schedule:\tlinear\n\tcheckpoint_interval:\t200000\n\tnetwork_settings:\t\n\t  normalize:\tFalse\n\t  hidden_units:\t256\n\t  num_layers:\t2\n\t  vis_encode_type:\tsimple\n\t  memory:\tNone\n\t  goal_conditioning_type:\thyper\n\t  deterministic:\tFalse\n\treward_signals:\t\n\t  extrinsic:\t\n\t    gamma:\t0.99\n\t    strength:\t1.0\n\t    network_settings:\t\n\t      normalize:\tFalse\n\t      hidden_units:\t128\n\t      num_layers:\t2\n\t      vis_encode_type:\tsimple\n\t      memory:\tNone\n\t      goal_conditioning_type:\thyper\n\t      deterministic:\tFalse\n\tinit_path:\tNone\n\tkeep_checkpoints:\t5\n\teven_checkpoints:\tFalse\n\tmax_steps:\t1000000\n\ttime_horizon:\t64\n\tsummary_freq:\t10000\n\tthreaded:\tFalse\n\tself_play:\tNone\n\tbehavioral_cloning:\tNone\n[INFO] Resuming from results/SnowballTarget1/SnowballTarget.\n[INFO] Resuming training from step 199984.\n[INFO] SnowballTarget. Step: 200000. Time Elapsed: 1.629 s. No episode was completed since last summary. Training.\n============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-199984.onnx\n[INFO] SnowballTarget. Step: 210000. Time Elapsed: 19.013 s. Mean Reward: 24.909. Std of Reward: 2.475. Training.\n[INFO] SnowballTarget. Step: 220000. Time Elapsed: 37.747 s. Mean Reward: 24.636. Std of Reward: 2.307. Training.\n[INFO] SnowballTarget. Step: 230000. Time Elapsed: 55.985 s. Mean Reward: 25.227. Std of Reward: 2.204. Training.\n[INFO] SnowballTarget. Step: 240000. Time Elapsed: 74.304 s. Mean Reward: 25.218. Std of Reward: 2.592. Training.\n[INFO] SnowballTarget. Step: 250000. Time Elapsed: 92.591 s. Mean Reward: 24.864. Std of Reward: 2.904. Training.\n[INFO] SnowballTarget. Step: 260000. Time Elapsed: 111.120 s. Mean Reward: 25.036. Std of Reward: 2.264. Training.\n[INFO] SnowballTarget. Step: 270000. Time Elapsed: 129.744 s. Mean Reward: 26.205. Std of Reward: 1.816. Training.\n[INFO] SnowballTarget. Step: 280000. Time Elapsed: 148.789 s. Mean Reward: 25.509. Std of Reward: 2.070. Training.\n[INFO] SnowballTarget. Step: 290000. Time Elapsed: 165.501 s. Mean Reward: 25.795. Std of Reward: 2.519. Training.\n[INFO] SnowballTarget. Step: 300000. Time Elapsed: 184.637 s. Mean Reward: 25.945. Std of Reward: 2.136. Training.\n[INFO] SnowballTarget. Step: 310000. Time Elapsed: 203.207 s. Mean Reward: 25.982. Std of Reward: 2.461. Training.\n[INFO] SnowballTarget. Step: 320000. Time Elapsed: 220.336 s. Mean Reward: 26.455. Std of Reward: 2.189. Training.\n[INFO] SnowballTarget. Step: 330000. Time Elapsed: 238.905 s. Mean Reward: 25.673. Std of Reward: 2.081. Training.\n[INFO] SnowballTarget. Step: 340000. Time Elapsed: 256.520 s. Mean Reward: 25.682. Std of Reward: 2.353. Training.\n[INFO] SnowballTarget. Step: 350000. Time Elapsed: 274.644 s. Mean Reward: 26.400. Std of Reward: 2.179. Training.\n[INFO] SnowballTarget. Step: 360000. Time Elapsed: 292.174 s. Mean Reward: 26.091. Std of Reward: 2.294. Training.\n[INFO] SnowballTarget. Step: 370000. Time Elapsed: 310.135 s. Mean Reward: 25.909. Std of Reward: 2.391. Training.\n[INFO] SnowballTarget. Step: 380000. Time Elapsed: 327.947 s. Mean Reward: 26.364. Std of Reward: 2.186. Training.\n[INFO] SnowballTarget. Step: 390000. Time Elapsed: 347.061 s. Mean Reward: 27.018. Std of Reward: 2.111. Training.\n[INFO] SnowballTarget. Step: 400000. Time Elapsed: 364.352 s. Mean Reward: 26.091. Std of Reward: 1.940. Training.\n============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-399968.onnx\n[INFO] SnowballTarget. Step: 410000. Time Elapsed: 383.094 s. Mean Reward: 26.727. Std of Reward: 2.178. Training.\n[INFO] SnowballTarget. Step: 420000. Time Elapsed: 402.364 s. Mean Reward: 26.582. Std of Reward: 2.349. Training.\n[INFO] SnowballTarget. Step: 430000. Time Elapsed: 418.857 s. Mean Reward: 25.886. Std of Reward: 2.525. Training.\n[INFO] SnowballTarget. Step: 440000. Time Elapsed: 438.141 s. Mean Reward: 26.236. Std of Reward: 2.140. Training.\n[INFO] SnowballTarget. Step: 450000. Time Elapsed: 456.119 s. Mean Reward: 26.523. Std of Reward: 2.221. Training.\n[INFO] SnowballTarget. Step: 460000. Time Elapsed: 474.642 s. Mean Reward: 25.945. Std of Reward: 2.611. Training.\n[INFO] SnowballTarget. Step: 470000. Time Elapsed: 492.296 s. Mean Reward: 26.682. Std of Reward: 2.353. Training.\n[INFO] SnowballTarget. Step: 480000. Time Elapsed: 510.310 s. Mean Reward: 26.600. Std of Reward: 2.023. Training.\n[INFO] SnowballTarget. Step: 490000. Time Elapsed: 528.375 s. Mean Reward: 26.250. Std of Reward: 2.861. Training.\n[INFO] SnowballTarget. Step: 500000. Time Elapsed: 547.245 s. Mean Reward: 26.855. Std of Reward: 1.566. Training.\n[INFO] SnowballTarget. Step: 510000. Time Elapsed: 563.757 s. Mean Reward: 26.614. Std of Reward: 2.025. Training.\n[INFO] SnowballTarget. Step: 520000. Time Elapsed: 582.670 s. Mean Reward: 27.236. Std of Reward: 2.191. Training.\n[INFO] SnowballTarget. Step: 530000. Time Elapsed: 601.421 s. Mean Reward: 27.018. Std of Reward: 2.136. Training.\n[INFO] SnowballTarget. Step: 540000. Time Elapsed: 618.274 s. Mean Reward: 26.705. Std of Reward: 2.360. Training.\n[INFO] SnowballTarget. Step: 550000. Time Elapsed: 636.728 s. Mean Reward: 26.945. Std of Reward: 2.084. Training.\n[INFO] SnowballTarget. Step: 560000. Time Elapsed: 654.531 s. Mean Reward: 26.977. Std of Reward: 1.631. Training.\n[INFO] SnowballTarget. Step: 570000. Time Elapsed: 672.480 s. Mean Reward: 26.800. Std of Reward: 2.022. Training.\n[INFO] SnowballTarget. Step: 580000. Time Elapsed: 689.968 s. Mean Reward: 26.795. Std of Reward: 2.191. Training.\n[INFO] SnowballTarget. Step: 590000. Time Elapsed: 707.380 s. Mean Reward: 27.491. Std of Reward: 1.934. Training.\n[INFO] SnowballTarget. Step: 600000. Time Elapsed: 724.653 s. Mean Reward: 27.500. Std of Reward: 1.865. Training.\n============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-599976.onnx\n[INFO] SnowballTarget. Step: 610000. Time Elapsed: 743.710 s. Mean Reward: 27.309. Std of Reward: 2.173. Training.\n[INFO] SnowballTarget. Step: 620000. Time Elapsed: 760.940 s. Mean Reward: 26.341. Std of Reward: 2.131. Training.\n[INFO] SnowballTarget. Step: 630000. Time Elapsed: 779.676 s. Mean Reward: 26.400. Std of Reward: 2.085. Training.\n[INFO] SnowballTarget. Step: 640000. Time Elapsed: 798.535 s. Mean Reward: 27.018. Std of Reward: 1.931. Training.\n[INFO] SnowballTarget. Step: 650000. Time Elapsed: 815.239 s. Mean Reward: 27.136. Std of Reward: 2.029. Training.\n[INFO] SnowballTarget. Step: 660000. Time Elapsed: 834.252 s. Mean Reward: 27.400. Std of Reward: 1.825. Training.\n[INFO] SnowballTarget. Step: 670000. Time Elapsed: 852.775 s. Mean Reward: 27.614. Std of Reward: 1.921. Training.\n[INFO] SnowballTarget. Step: 680000. Time Elapsed: 870.797 s. Mean Reward: 27.055. Std of Reward: 2.136. Training.\n[INFO] SnowballTarget. Step: 690000. Time Elapsed: 888.840 s. Mean Reward: 27.273. Std of Reward: 1.737. Training.\n[INFO] SnowballTarget. Step: 700000. Time Elapsed: 907.005 s. Mean Reward: 26.800. Std of Reward: 1.976. Training.\n[INFO] SnowballTarget. Step: 710000. Time Elapsed: 924.374 s. Mean Reward: 27.182. Std of Reward: 1.934. Training.\n[INFO] SnowballTarget. Step: 720000. Time Elapsed: 943.753 s. Mean Reward: 26.964. Std of Reward: 1.926. Training.\n[INFO] SnowballTarget. Step: 730000. Time Elapsed: 960.548 s. Mean Reward: 27.136. Std of Reward: 2.138. Training.\n[INFO] SnowballTarget. Step: 740000. Time Elapsed: 979.223 s. Mean Reward: 27.127. Std of Reward: 1.849. Training.\n[INFO] SnowballTarget. Step: 750000. Time Elapsed: 997.664 s. Mean Reward: 27.618. Std of Reward: 2.170. Training.\n[INFO] SnowballTarget. Step: 760000. Time Elapsed: 1014.738 s. Mean Reward: 27.295. Std of Reward: 1.890. Training.\n[INFO] SnowballTarget. Step: 770000. Time Elapsed: 1033.298 s. Mean Reward: 27.327. Std of Reward: 1.695. Training.\n[INFO] SnowballTarget. Step: 780000. Time Elapsed: 1051.449 s. Mean Reward: 27.205. Std of Reward: 2.292. Training.\n[INFO] SnowballTarget. Step: 790000. Time Elapsed: 1069.487 s. Mean Reward: 27.418. Std of Reward: 2.051. Training.\n[INFO] SnowballTarget. Step: 800000. Time Elapsed: 1087.116 s. Mean Reward: 27.114. Std of Reward: 1.945. Training.\n============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-799984.onnx\n[INFO] SnowballTarget. Step: 810000. Time Elapsed: 1105.034 s. Mean Reward: 27.091. Std of Reward: 1.822. Training.\n[INFO] SnowballTarget. Step: 820000. Time Elapsed: 1123.226 s. Mean Reward: 27.705. Std of Reward: 1.890. Training.\n[INFO] SnowballTarget. Step: 830000. Time Elapsed: 1141.849 s. Mean Reward: 27.127. Std of Reward: 2.081. Training.\n[INFO] SnowballTarget. Step: 840000. Time Elapsed: 1158.724 s. Mean Reward: 26.955. Std of Reward: 2.142. Training.\n[INFO] SnowballTarget. Step: 850000. Time Elapsed: 1177.338 s. Mean Reward: 27.273. Std of Reward: 1.793. Training.\n[INFO] SnowballTarget. Step: 860000. Time Elapsed: 1196.156 s. Mean Reward: 27.945. Std of Reward: 2.004. Training.\n[INFO] SnowballTarget. Step: 870000. Time Elapsed: 1212.851 s. Mean Reward: 27.500. Std of Reward: 2.083. Training.\n[INFO] SnowballTarget. Step: 880000. Time Elapsed: 1232.091 s. Mean Reward: 27.436. Std of Reward: 1.970. Training.\n[INFO] SnowballTarget. Step: 890000. Time Elapsed: 1250.109 s. Mean Reward: 27.841. Std of Reward: 1.770. Training.\n[INFO] SnowballTarget. Step: 900000. Time Elapsed: 1268.321 s. Mean Reward: 27.218. Std of Reward: 2.086. Training.\n[INFO] SnowballTarget. Step: 910000. Time Elapsed: 1286.310 s. Mean Reward: 27.591. Std of Reward: 1.762. Training.\n[INFO] SnowballTarget. Step: 920000. Time Elapsed: 1304.378 s. Mean Reward: 27.473. Std of Reward: 1.953. Training.\n[INFO] SnowballTarget. Step: 930000. Time Elapsed: 1322.035 s. Mean Reward: 27.659. Std of Reward: 2.121. Training.\n[INFO] SnowballTarget. Step: 940000. Time Elapsed: 1340.872 s. Mean Reward: 27.164. Std of Reward: 1.837. Training.\n[INFO] SnowballTarget. Step: 950000. Time Elapsed: 1357.849 s. Mean Reward: 27.318. Std of Reward: 1.427. Training.\n[INFO] SnowballTarget. Step: 960000. Time Elapsed: 1376.915 s. Mean Reward: 27.709. Std of Reward: 2.394. Training.\n[INFO] SnowballTarget. Step: 970000. Time Elapsed: 1395.783 s. Mean Reward: 27.655. Std of Reward: 2.108. Training.\n[INFO] SnowballTarget. Step: 980000. Time Elapsed: 1412.830 s. Mean Reward: 27.750. Std of Reward: 1.734. Training.\n[INFO] SnowballTarget. Step: 990000. Time Elapsed: 1431.565 s. Mean Reward: 27.364. Std of Reward: 2.066. Training.\n[INFO] SnowballTarget. Step: 1000000. Time Elapsed: 1449.492 s. Mean Reward: 27.614. Std of Reward: 2.134. Training.\n============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-999992.onnx\n============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n[INFO] Exported results/SnowballTarget1/SnowballTarget/SnowballTarget-1000696.onnx\n[INFO] Copied results/SnowballTarget1/SnowballTarget/SnowballTarget-1000696.onnx to results/SnowballTarget1/SnowballTarget.onnx.\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"## Part 2: Pyramids üèõÔ∏è\n\nTrain an agent to press a button, navigate to a pyramid, knock it over, and reach the gold brick using **curiosity-driven exploration**.","metadata":{}},{"cell_type":"markdown","source":"### Create the Pyramids config file (with curiosity)","metadata":{}},{"cell_type":"code","source":"pyramids_config = \"\"\"\nbehaviors:\n  Pyramids:\n    trainer_type: ppo\n    hyperparameters:\n      batch_size: 128\n      buffer_size: 2048\n      learning_rate: 0.0003\n      beta: 0.01\n      epsilon: 0.2\n      lambd: 0.95\n      num_epoch: 3\n      learning_rate_schedule: linear\n    network_settings:\n      normalize: false\n      hidden_units: 256\n      num_layers: 2\n      vis_encode_type: simple\n    reward_signals:\n      extrinsic:\n        gamma: 0.99\n        strength: 1.0\n      curiosity:\n        gamma: 0.99\n        strength: 0.02\n        encoding_size: 256\n        learning_rate: 0.0003\n    checkpoint_interval: 200000\n    keep_checkpoints: 5\n    max_steps: 1500000\n    time_horizon: 128\n    summary_freq: 10000\n\"\"\"\n\nwith open(\"/kaggle/working/ml-agents/config/ppo/Pyramids.yaml\", \"w\") as f:\n    f.write(pyramids_config)\n\nprint(\"‚úÖ Pyramids config written (with curiosity reward) to: /kaggle/working/ml-agents/config/ppo/Pyramids.yaml\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T21:18:19.035885Z","iopub.execute_input":"2026-02-24T21:18:19.036227Z","iopub.status.idle":"2026-02-24T21:18:19.042197Z","shell.execute_reply.started":"2026-02-24T21:18:19.036196Z","shell.execute_reply":"2026-02-24T21:18:19.041617Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Pyramids config written (with curiosity reward) to: /kaggle/working/ml-agents/config/ppo/Pyramids.yaml\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"### Train Pyramids agent\n\nTraining takes ~45‚Äì60 minutes. Curiosity helps the agent explore and discover the pyramid task.","metadata":{}},{"cell_type":"code","source":"!/kaggle/working/mlagents-env/bin/mlagents-learn \\\n    /kaggle/working/ml-agents/config/ppo/Pyramids.yaml \\\n    --env=./training-envs-executables/Pyramids/Pyramids/Pyramids \\\n    --run-id=\"Pyramids1\" \\\n    --no-graphics \\\n    --force","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T21:25:53.746366Z","iopub.execute_input":"2026-02-24T21:25:53.747239Z","iopub.status.idle":"2026-02-24T22:24:06.809975Z","shell.execute_reply.started":"2026-02-24T21:25:53.747204Z","shell.execute_reply":"2026-02-24T22:24:06.809036Z"}},"outputs":[{"name":"stdout","text":"[WARNING] 'encoding_size' was deprecated for RewardSignals. Please use network_settings.\n\n            ‚îê  ‚ïñ\n        ‚ïì‚ïñ‚ï¨‚îÇ‚ï°  ‚îÇ‚îÇ‚ï¨‚ïñ‚ïñ\n    ‚ïì‚ïñ‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚îò  ‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚ï¨‚ïñ\n ‚ïñ‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚ï¨‚ïú        ‚ïô‚ï¨‚îÇ‚îÇ‚îÇ‚îÇ‚îÇ‚ïñ‚ïñ                               ‚ïó‚ïó‚ïó\n ‚ï¨‚ï¨‚ï¨‚ï¨‚ïñ‚îÇ‚îÇ‚ï¶‚ïñ        ‚ïñ‚ï¨‚îÇ‚îÇ‚ïó‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£             ‚ïú‚ïú‚ïú  ‚ïü‚ï£‚ï£\n ‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ïñ‚îÇ‚ï¨‚ïñ‚ïñ‚ïì‚ï¨‚ï™‚îÇ‚ïì‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£ ‚ïí‚ï£‚ï£‚ïñ‚ïó‚ï£‚ï£‚ï£‚ïó   ‚ï£‚ï£‚ï£ ‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£ ‚ïü‚ï£‚ï£‚ïñ   ‚ï£‚ï£‚ï£\n ‚ï¨‚ï¨‚ï¨‚ï¨‚îê  ‚ïô‚ï¨‚ï¨‚ï¨‚ï¨‚îÇ‚ïì‚ï£‚ï£‚ï£‚ïù‚ïú  ‚ï´‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£ ‚ïü‚ï£‚ï£‚ï£‚ïô ‚ïô‚ï£‚ï£‚ï£  ‚ï£‚ï£‚ï£ ‚ïô‚ïü‚ï£‚ï£‚ïú‚ïô  ‚ï´‚ï£‚ï£  ‚ïü‚ï£‚ï£\n ‚ï¨‚ï¨‚ï¨‚ï¨‚îê     ‚ïô‚ï¨‚ï¨‚ï£‚ï£      ‚ï´‚ï£‚ï£‚ï£‚ï¨      ‚ïü‚ï£‚ï£‚ï¨    ‚ïü‚ï£‚ï£‚ï£ ‚ïü‚ï£‚ï£‚ï¨   ‚ï£‚ï£‚ï£  ‚ï£‚ï£‚ï£  ‚ïü‚ï£‚ï£     ‚ï£‚ï£‚ï£‚îå‚ï£‚ï£‚ïú\n ‚ï¨‚ï¨‚ï¨‚ïú       ‚ï¨‚ï¨‚ï£‚ï£      ‚ïô‚ïù‚ï£‚ï£‚ï¨      ‚ïô‚ï£‚ï£‚ï£‚ïó‚ïñ‚ïì‚ïó‚ï£‚ï£‚ï£‚ïú ‚ïü‚ï£‚ï£‚ï¨   ‚ï£‚ï£‚ï£  ‚ï£‚ï£‚ï£  ‚ïü‚ï£‚ï£‚ï¶‚ïì    ‚ï£‚ï£‚ï£‚ï£‚ï£\n ‚ïô   ‚ïì‚ï¶‚ïñ    ‚ï¨‚ï¨‚ï£‚ï£   ‚ïì‚ïó‚ïó‚ïñ            ‚ïô‚ïù‚ï£‚ï£‚ï£‚ï£‚ïù‚ïú   ‚ïò‚ïù‚ïù‚ïú   ‚ïù‚ïù‚ïù  ‚ïù‚ïù‚ïù   ‚ïô‚ï£‚ï£‚ï£    ‚ïü‚ï£‚ï£‚ï£\n   ‚ï©‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¶‚ï¶‚ï¨‚ï¨‚ï£‚ï£‚ïó‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ïù                                             ‚ï´‚ï£‚ï£‚ï£‚ï£\n      ‚ïô‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï¨‚ï£‚ï£‚ï£‚ï£‚ï£‚ï£‚ïù‚ïú\n          ‚ïô‚ï¨‚ï¨‚ï¨‚ï£‚ï£‚ï£‚ïú\n             ‚ïô\n        \n Version information:\n  ml-agents: 1.1.0,\n  ml-agents-envs: 1.1.0,\n  Communicator API: 1.5.0,\n  PyTorch: 2.0.1+cpu\n[INFO] Connected to Unity environment with package version 2.2.1-exp.1 and communication version 1.5.0\n[INFO] Connected new brain: Pyramids?team=0\n[INFO] Hyperparameters for behavior name Pyramids: \n\ttrainer_type:\tppo\n\thyperparameters:\t\n\t  batch_size:\t128\n\t  buffer_size:\t2048\n\t  learning_rate:\t0.0003\n\t  beta:\t0.01\n\t  epsilon:\t0.2\n\t  lambd:\t0.95\n\t  num_epoch:\t3\n\t  shared_critic:\tFalse\n\t  learning_rate_schedule:\tlinear\n\t  beta_schedule:\tlinear\n\t  epsilon_schedule:\tlinear\n\tcheckpoint_interval:\t200000\n\tnetwork_settings:\t\n\t  normalize:\tFalse\n\t  hidden_units:\t256\n\t  num_layers:\t2\n\t  vis_encode_type:\tsimple\n\t  memory:\tNone\n\t  goal_conditioning_type:\thyper\n\t  deterministic:\tFalse\n\treward_signals:\t\n\t  extrinsic:\t\n\t    gamma:\t0.99\n\t    strength:\t1.0\n\t    network_settings:\t\n\t      normalize:\tFalse\n\t      hidden_units:\t128\n\t      num_layers:\t2\n\t      vis_encode_type:\tsimple\n\t      memory:\tNone\n\t      goal_conditioning_type:\thyper\n\t      deterministic:\tFalse\n\t  curiosity:\t\n\t    gamma:\t0.99\n\t    strength:\t0.02\n\t    network_settings:\t\n\t      normalize:\tFalse\n\t      hidden_units:\t256\n\t      num_layers:\t2\n\t      vis_encode_type:\tsimple\n\t      memory:\tNone\n\t      goal_conditioning_type:\thyper\n\t      deterministic:\tFalse\n\t    learning_rate:\t0.0003\n\t    encoding_size:\t256\n\tinit_path:\tNone\n\tkeep_checkpoints:\t5\n\teven_checkpoints:\tFalse\n\tmax_steps:\t1500000\n\ttime_horizon:\t128\n\tsummary_freq:\t10000\n\tthreaded:\tFalse\n\tself_play:\tNone\n\tbehavioral_cloning:\tNone\n/kaggle/working/mlagents-env/lib/python3.10/site-packages/mlagents/trainers/torch_entities/utils.py:289: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3571.)\n  torch.nn.functional.one_hot(_act.T, action_size[i]).float()\n[INFO] Pyramids. Step: 10000. Time Elapsed: 17.756 s. No episode was completed since last summary. Training.\n[INFO] Pyramids. Step: 20000. Time Elapsed: 33.986 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 30000. Time Elapsed: 53.988 s. No episode was completed since last summary. Training.\n[INFO] Pyramids. Step: 40000. Time Elapsed: 72.397 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 50000. Time Elapsed: 94.296 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 60000. Time Elapsed: 113.265 s. No episode was completed since last summary. Training.\n[INFO] Pyramids. Step: 70000. Time Elapsed: 134.724 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 80000. Time Elapsed: 154.479 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 90000. Time Elapsed: 177.123 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 100000. Time Elapsed: 196.413 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 110000. Time Elapsed: 217.226 s. No episode was completed since last summary. Training.\n[INFO] Pyramids. Step: 120000. Time Elapsed: 236.291 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 130000. Time Elapsed: 258.261 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 140000. Time Elapsed: 279.391 s. Mean Reward: 1.636. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 150000. Time Elapsed: 301.032 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 160000. Time Elapsed: 322.935 s. Mean Reward: -0.859. Std of Reward: 0.527. Training.\n[INFO] Pyramids. Step: 170000. Time Elapsed: 345.800 s. Mean Reward: -0.999. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 180000. Time Elapsed: 371.130 s. Mean Reward: -0.845. Std of Reward: 0.579. Training.\n[INFO] Pyramids. Step: 190000. Time Elapsed: 390.961 s. Mean Reward: -0.409. Std of Reward: 1.023. Training.\n[INFO] Pyramids. Step: 200000. Time Elapsed: 413.524 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n[INFO] Exported results/Pyramids1/Pyramids/Pyramids-199893.onnx\n[INFO] Pyramids. Step: 210000. Time Elapsed: 435.773 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 220000. Time Elapsed: 455.510 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 230000. Time Elapsed: 476.366 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 240000. Time Elapsed: 499.116 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 250000. Time Elapsed: 517.418 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 260000. Time Elapsed: 541.526 s. Mean Reward: -0.857. Std of Reward: 0.535. Training.\n[INFO] Pyramids. Step: 270000. Time Elapsed: 561.436 s. Mean Reward: -0.362. Std of Reward: 1.104. Training.\n[INFO] Pyramids. Step: 280000. Time Elapsed: 582.724 s. Mean Reward: -0.651. Std of Reward: 0.869. Training.\n[INFO] Pyramids. Step: 290000. Time Elapsed: 606.796 s. Mean Reward: -0.854. Std of Reward: 0.527. Training.\n[INFO] Pyramids. Step: 300000. Time Elapsed: 626.147 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 310000. Time Elapsed: 648.971 s. Mean Reward: -0.830. Std of Reward: 0.590. Training.\n[INFO] Pyramids. Step: 320000. Time Elapsed: 670.158 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 330000. Time Elapsed: 689.621 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 340000. Time Elapsed: 712.316 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 350000. Time Elapsed: 733.511 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 360000. Time Elapsed: 756.097 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 370000. Time Elapsed: 777.613 s. Mean Reward: -0.844. Std of Reward: 0.583. Training.\n[INFO] Pyramids. Step: 380000. Time Elapsed: 798.685 s. Mean Reward: -0.557. Std of Reward: 0.886. Training.\n[INFO] Pyramids. Step: 390000. Time Elapsed: 822.755 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 400000. Time Elapsed: 844.765 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n[INFO] Exported results/Pyramids1/Pyramids/Pyramids-399998.onnx\n[INFO] Pyramids. Step: 410000. Time Elapsed: 867.054 s. Mean Reward: -0.129. Std of Reward: 1.238. Training.\n[INFO] Pyramids. Step: 420000. Time Elapsed: 889.200 s. Mean Reward: -0.665. Std of Reward: 0.821. Training.\n[INFO] Pyramids. Step: 430000. Time Elapsed: 910.580 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 440000. Time Elapsed: 929.504 s. Mean Reward: -0.806. Std of Reward: 0.672. Training.\n[INFO] Pyramids. Step: 450000. Time Elapsed: 954.202 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 460000. Time Elapsed: 974.237 s. Mean Reward: -0.580. Std of Reward: 1.029. Training.\n[INFO] Pyramids. Step: 470000. Time Elapsed: 997.153 s. Mean Reward: -0.771. Std of Reward: 0.760. Training.\n[INFO] Pyramids. Step: 480000. Time Elapsed: 1021.295 s. Mean Reward: -0.803. Std of Reward: 0.681. Training.\n[INFO] Pyramids. Step: 490000. Time Elapsed: 1044.781 s. Mean Reward: -0.575. Std of Reward: 0.949. Training.\n[INFO] Pyramids. Step: 500000. Time Elapsed: 1071.086 s. Mean Reward: -0.564. Std of Reward: 0.874. Training.\n[INFO] Pyramids. Step: 510000. Time Elapsed: 1093.338 s. Mean Reward: -0.523. Std of Reward: 0.954. Training.\n[INFO] Pyramids. Step: 520000. Time Elapsed: 1120.895 s. Mean Reward: -0.499. Std of Reward: 0.964. Training.\n[INFO] Pyramids. Step: 530000. Time Elapsed: 1146.384 s. Mean Reward: -0.459. Std of Reward: 0.991. Training.\n[INFO] Pyramids. Step: 540000. Time Elapsed: 1171.356 s. Mean Reward: -0.399. Std of Reward: 1.042. Training.\n[INFO] Pyramids. Step: 550000. Time Elapsed: 1196.973 s. Mean Reward: -0.087. Std of Reward: 1.086. Training.\n[INFO] Pyramids. Step: 560000. Time Elapsed: 1222.421 s. Mean Reward: -0.790. Std of Reward: 0.665. Training.\n[INFO] Pyramids. Step: 570000. Time Elapsed: 1248.902 s. Mean Reward: -0.496. Std of Reward: 1.069. Training.\n[INFO] Pyramids. Step: 580000. Time Elapsed: 1274.425 s. Mean Reward: -0.027. Std of Reward: 1.163. Training.\n[INFO] Pyramids. Step: 590000. Time Elapsed: 1299.765 s. Mean Reward: -0.486. Std of Reward: 0.962. Training.\n[INFO] Pyramids. Step: 600000. Time Elapsed: 1325.589 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n[INFO] Exported results/Pyramids1/Pyramids/Pyramids-599991.onnx\n[INFO] Pyramids. Step: 610000. Time Elapsed: 1347.930 s. Mean Reward: -0.535. Std of Reward: 0.937. Training.\n[INFO] Pyramids. Step: 620000. Time Elapsed: 1367.798 s. Mean Reward: -0.472. Std of Reward: 0.998. Training.\n[INFO] Pyramids. Step: 630000. Time Elapsed: 1390.923 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 640000. Time Elapsed: 1416.431 s. Mean Reward: -0.602. Std of Reward: 0.977. Training.\n[INFO] Pyramids. Step: 650000. Time Elapsed: 1436.191 s. Mean Reward: -0.509. Std of Reward: 1.046. Training.\n[INFO] Pyramids. Step: 660000. Time Elapsed: 1459.233 s. Mean Reward: -0.779. Std of Reward: 0.662. Training.\n[INFO] Pyramids. Step: 670000. Time Elapsed: 1481.262 s. Mean Reward: -0.203. Std of Reward: 1.136. Training.\n[INFO] Pyramids. Step: 680000. Time Elapsed: 1502.378 s. Mean Reward: -0.511. Std of Reward: 0.979. Training.\n[INFO] Pyramids. Step: 690000. Time Elapsed: 1526.764 s. Mean Reward: -0.773. Std of Reward: 0.716. Training.\n[INFO] Pyramids. Step: 700000. Time Elapsed: 1551.514 s. Mean Reward: -0.546. Std of Reward: 0.909. Training.\n[INFO] Pyramids. Step: 710000. Time Elapsed: 1575.423 s. Mean Reward: -0.305. Std of Reward: 1.069. Training.\n[INFO] Pyramids. Step: 720000. Time Elapsed: 1596.748 s. Mean Reward: -0.637. Std of Reward: 0.856. Training.\n[INFO] Pyramids. Step: 730000. Time Elapsed: 1620.093 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 740000. Time Elapsed: 1644.521 s. Mean Reward: 0.016. Std of Reward: 1.218. Training.\n[INFO] Pyramids. Step: 750000. Time Elapsed: 1670.498 s. Mean Reward: -0.518. Std of Reward: 1.031. Training.\n[INFO] Pyramids. Step: 760000. Time Elapsed: 1692.517 s. Mean Reward: -0.513. Std of Reward: 0.976. Training.\n[INFO] Pyramids. Step: 770000. Time Elapsed: 1717.586 s. Mean Reward: -0.299. Std of Reward: 1.124. Training.\n[INFO] Pyramids. Step: 780000. Time Elapsed: 1741.320 s. Mean Reward: -0.451. Std of Reward: 1.042. Training.\n[INFO] Pyramids. Step: 790000. Time Elapsed: 1764.947 s. Mean Reward: -1.000. Std of Reward: 0.000. Training.\n[INFO] Pyramids. Step: 800000. Time Elapsed: 1790.069 s. Mean Reward: -0.218. Std of Reward: 1.174. Training.\n============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n[INFO] Exported results/Pyramids1/Pyramids/Pyramids-799915.onnx\n[INFO] Pyramids. Step: 810000. Time Elapsed: 1814.915 s. Mean Reward: 0.215. Std of Reward: 1.237. Training.\n[INFO] Pyramids. Step: 820000. Time Elapsed: 1837.599 s. Mean Reward: -0.109. Std of Reward: 1.141. Training.\n[INFO] Pyramids. Step: 830000. Time Elapsed: 1862.661 s. Mean Reward: -0.284. Std of Reward: 1.076. Training.\n[INFO] Pyramids. Step: 840000. Time Elapsed: 1887.899 s. Mean Reward: -0.203. Std of Reward: 1.136. Training.\n[INFO] Pyramids. Step: 850000. Time Elapsed: 1910.626 s. Mean Reward: -0.367. Std of Reward: 1.048. Training.\n[INFO] Pyramids. Step: 860000. Time Elapsed: 1936.349 s. Mean Reward: -0.400. Std of Reward: 1.047. Training.\n[INFO] Pyramids. Step: 870000. Time Elapsed: 1960.875 s. Mean Reward: 0.563. Std of Reward: 1.121. Training.\n[INFO] Pyramids. Step: 880000. Time Elapsed: 1985.631 s. Mean Reward: -0.589. Std of Reward: 0.872. Training.\n[INFO] Pyramids. Step: 890000. Time Elapsed: 2011.212 s. Mean Reward: -0.325. Std of Reward: 1.105. Training.\n[INFO] Pyramids. Step: 900000. Time Elapsed: 2035.333 s. Mean Reward: -0.152. Std of Reward: 1.126. Training.\n[INFO] Pyramids. Step: 910000. Time Elapsed: 2057.371 s. Mean Reward: -0.774. Std of Reward: 0.713. Training.\n[INFO] Pyramids. Step: 920000. Time Elapsed: 2079.570 s. Mean Reward: -0.107. Std of Reward: 1.191. Training.\n[INFO] Pyramids. Step: 930000. Time Elapsed: 2106.338 s. Mean Reward: -0.751. Std of Reward: 0.785. Training.\n[INFO] Pyramids. Step: 940000. Time Elapsed: 2133.242 s. Mean Reward: -0.491. Std of Reward: 0.976. Training.\n[INFO] Pyramids. Step: 950000. Time Elapsed: 2154.992 s. Mean Reward: 0.402. Std of Reward: 1.155. Training.\n[INFO] Pyramids. Step: 960000. Time Elapsed: 2179.480 s. Mean Reward: -0.421. Std of Reward: 1.011. Training.\n[INFO] Pyramids. Step: 970000. Time Elapsed: 2205.585 s. Mean Reward: -0.678. Std of Reward: 0.790. Training.\n[INFO] Pyramids. Step: 980000. Time Elapsed: 2228.276 s. Mean Reward: 0.160. Std of Reward: 1.278. Training.\n[INFO] Pyramids. Step: 990000. Time Elapsed: 2253.409 s. Mean Reward: -0.115. Std of Reward: 1.191. Training.\n[INFO] Pyramids. Step: 1000000. Time Elapsed: 2281.976 s. Mean Reward: -0.107. Std of Reward: 1.097. Training.\n============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n[INFO] Exported results/Pyramids1/Pyramids/Pyramids-999967.onnx\n[INFO] Pyramids. Step: 1010000. Time Elapsed: 2304.828 s. Mean Reward: 0.037. Std of Reward: 1.313. Training.\n[INFO] Pyramids. Step: 1020000. Time Elapsed: 2327.869 s. Mean Reward: -0.344. Std of Reward: 1.075. Training.\n[INFO] Pyramids. Step: 1030000. Time Elapsed: 2353.226 s. Mean Reward: 0.436. Std of Reward: 1.185. Training.\n[INFO] Pyramids. Step: 1040000. Time Elapsed: 2376.004 s. Mean Reward: -0.738. Std of Reward: 0.785. Training.\n[INFO] Pyramids. Step: 1050000. Time Elapsed: 2398.931 s. Mean Reward: -0.697. Std of Reward: 0.855. Training.\n[INFO] Pyramids. Step: 1060000. Time Elapsed: 2422.084 s. Mean Reward: -0.012. Std of Reward: 1.215. Training.\n[INFO] Pyramids. Step: 1070000. Time Elapsed: 2447.028 s. Mean Reward: -0.007. Std of Reward: 1.093. Training.\n[INFO] Pyramids. Step: 1080000. Time Elapsed: 2469.708 s. Mean Reward: 0.470. Std of Reward: 1.222. Training.\n[INFO] Pyramids. Step: 1090000. Time Elapsed: 2496.017 s. Mean Reward: 0.255. Std of Reward: 1.196. Training.\n[INFO] Pyramids. Step: 1100000. Time Elapsed: 2522.231 s. Mean Reward: -0.292. Std of Reward: 1.084. Training.\n[INFO] Pyramids. Step: 1110000. Time Elapsed: 2546.351 s. Mean Reward: 0.057. Std of Reward: 1.165. Training.\n[INFO] Pyramids. Step: 1120000. Time Elapsed: 2572.098 s. Mean Reward: -0.155. Std of Reward: 1.267. Training.\n[INFO] Pyramids. Step: 1130000. Time Elapsed: 2600.307 s. Mean Reward: -0.486. Std of Reward: 0.964. Training.\n[INFO] Pyramids. Step: 1140000. Time Elapsed: 2628.436 s. Mean Reward: 0.099. Std of Reward: 1.247. Training.\n[INFO] Pyramids. Step: 1150000. Time Elapsed: 2652.555 s. Mean Reward: 0.016. Std of Reward: 1.288. Training.\n[INFO] Pyramids. Step: 1160000. Time Elapsed: 2677.288 s. Mean Reward: -0.164. Std of Reward: 1.108. Training.\n[INFO] Pyramids. Step: 1170000. Time Elapsed: 2702.759 s. Mean Reward: -0.051. Std of Reward: 1.264. Training.\n[INFO] Pyramids. Step: 1180000. Time Elapsed: 2727.691 s. Mean Reward: -0.002. Std of Reward: 1.234. Training.\n[INFO] Pyramids. Step: 1190000. Time Elapsed: 2751.381 s. Mean Reward: 0.058. Std of Reward: 1.254. Training.\n[INFO] Pyramids. Step: 1200000. Time Elapsed: 2775.015 s. Mean Reward: -0.804. Std of Reward: 0.619. Training.\n============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n[INFO] Exported results/Pyramids1/Pyramids/Pyramids-1199919.onnx\n[INFO] Pyramids. Step: 1210000. Time Elapsed: 2799.189 s. Mean Reward: 0.125. Std of Reward: 1.131. Training.\n[INFO] Pyramids. Step: 1220000. Time Elapsed: 2820.953 s. Mean Reward: 0.181. Std of Reward: 1.200. Training.\n[INFO] Pyramids. Step: 1230000. Time Elapsed: 2846.184 s. Mean Reward: -0.651. Std of Reward: 0.780. Training.\n[INFO] Pyramids. Step: 1240000. Time Elapsed: 2870.960 s. Mean Reward: 0.081. Std of Reward: 1.254. Training.\n[INFO] Pyramids. Step: 1250000. Time Elapsed: 2894.984 s. Mean Reward: 0.595. Std of Reward: 1.079. Training.\n[INFO] Pyramids. Step: 1260000. Time Elapsed: 2919.346 s. Mean Reward: 0.358. Std of Reward: 1.283. Training.\n[INFO] Pyramids. Step: 1270000. Time Elapsed: 2943.083 s. Mean Reward: 0.378. Std of Reward: 1.257. Training.\n[INFO] Pyramids. Step: 1280000. Time Elapsed: 2967.064 s. Mean Reward: -0.198. Std of Reward: 1.213. Training.\n[INFO] Pyramids. Step: 1290000. Time Elapsed: 2991.695 s. Mean Reward: -0.194. Std of Reward: 1.146. Training.\n[INFO] Pyramids. Step: 1300000. Time Elapsed: 3012.417 s. Mean Reward: 0.213. Std of Reward: 1.216. Training.\n[INFO] Pyramids. Step: 1310000. Time Elapsed: 3037.440 s. Mean Reward: -0.271. Std of Reward: 1.100. Training.\n[INFO] Pyramids. Step: 1320000. Time Elapsed: 3060.686 s. Mean Reward: 0.425. Std of Reward: 1.304. Training.\n[INFO] Pyramids. Step: 1330000. Time Elapsed: 3085.988 s. Mean Reward: -0.132. Std of Reward: 1.028. Training.\n[INFO] Pyramids. Step: 1340000. Time Elapsed: 3108.567 s. Mean Reward: -0.390. Std of Reward: 1.059. Training.\n[INFO] Pyramids. Step: 1350000. Time Elapsed: 3134.178 s. Mean Reward: 0.241. Std of Reward: 1.252. Training.\n[INFO] Pyramids. Step: 1360000. Time Elapsed: 3157.285 s. Mean Reward: 0.465. Std of Reward: 1.209. Training.\n[INFO] Pyramids. Step: 1370000. Time Elapsed: 3178.498 s. Mean Reward: -0.058. Std of Reward: 1.222. Training.\n[INFO] Pyramids. Step: 1380000. Time Elapsed: 3201.074 s. Mean Reward: -0.195. Std of Reward: 1.142. Training.\n[INFO] Pyramids. Step: 1390000. Time Elapsed: 3226.196 s. Mean Reward: 0.037. Std of Reward: 1.246. Training.\n[INFO] Pyramids. Step: 1400000. Time Elapsed: 3249.969 s. Mean Reward: -0.088. Std of Reward: 1.238. Training.\n============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n[INFO] Exported results/Pyramids1/Pyramids/Pyramids-1399964.onnx\n[INFO] Pyramids. Step: 1410000. Time Elapsed: 3272.763 s. Mean Reward: 0.017. Std of Reward: 1.213. Training.\n[INFO] Pyramids. Step: 1420000. Time Elapsed: 3296.189 s. Mean Reward: -0.210. Std of Reward: 1.124. Training.\n[INFO] Pyramids. Step: 1430000. Time Elapsed: 3321.810 s. Mean Reward: 0.540. Std of Reward: 1.164. Training.\n[INFO] Pyramids. Step: 1440000. Time Elapsed: 3348.786 s. Mean Reward: 0.216. Std of Reward: 1.234. Training.\n[INFO] Pyramids. Step: 1450000. Time Elapsed: 3373.464 s. Mean Reward: 0.120. Std of Reward: 1.276. Training.\n[INFO] Pyramids. Step: 1460000. Time Elapsed: 3397.313 s. Mean Reward: 0.166. Std of Reward: 1.262. Training.\n[INFO] Pyramids. Step: 1470000. Time Elapsed: 3420.263 s. Mean Reward: 0.331. Std of Reward: 1.139. Training.\n[INFO] Pyramids. Step: 1480000. Time Elapsed: 3442.837 s. Mean Reward: 0.397. Std of Reward: 1.190. Training.\n[INFO] Pyramids. Step: 1490000. Time Elapsed: 3467.505 s. Mean Reward: 0.249. Std of Reward: 1.263. Training.\n[INFO] Pyramids. Step: 1500000. Time Elapsed: 3490.427 s. Mean Reward: 0.826. Std of Reward: 1.129. Training.\n============== Diagnostic Run torch.onnx.export version 2.0.1+cpu ==============\nverbose: False, log level: Level.ERROR\n======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n\n[INFO] Exported results/Pyramids1/Pyramids/Pyramids-1500031.onnx\n[INFO] Copied results/Pyramids1/Pyramids/Pyramids-1500031.onnx to results/Pyramids1/Pyramids.onnx.\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"## Push agents to the ü§ó Hub\n\nWe use **Kaggle Secrets** for the HuggingFace token.","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n# notebook_login()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T21:14:30.107519Z","iopub.execute_input":"2026-02-24T21:14:30.107841Z","iopub.status.idle":"2026-02-24T21:14:30.595609Z","shell.execute_reply.started":"2026-02-24T21:14:30.107810Z","shell.execute_reply":"2026-02-24T21:14:30.594885Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"!git config --global credential.helper store","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T21:14:31.427514Z","iopub.execute_input":"2026-02-24T21:14:31.427839Z","iopub.status.idle":"2026-02-24T21:14:31.570012Z","shell.execute_reply.started":"2026-02-24T21:14:31.427814Z","shell.execute_reply":"2026-02-24T21:14:31.569191Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import HfApi, login\n\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\n\nlogin(token=hf_token, add_to_git_credential=True)\n\napi = HfApi()\nuser_info = api.whoami()\nprint(f\"‚úÖ Logged in as: {user_info['name']}\")\nprint(f\"‚úÖ Token has Write access: {user_info['auth']['type'] == 'WRITE'}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T21:14:34.420169Z","iopub.execute_input":"2026-02-24T21:14:34.420749Z","iopub.status.idle":"2026-02-24T21:14:35.169967Z","shell.execute_reply.started":"2026-02-24T21:14:34.420715Z","shell.execute_reply":"2026-02-24T21:14:35.169288Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Logged in as: Chiz\n‚úÖ Token has Write access: False\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"### Push SnowballTarget\n\n**Edit `--repo-id` to use your HuggingFace username**","metadata":{}},{"cell_type":"code","source":"!/kaggle/working/mlagents-env/bin/mlagents-push-to-hf \\\n    --run-id=\"SnowballTarget1\" \\\n    --local-dir=\"./results/SnowballTarget1\" \\\n    --repo-id=\"Chiz/ppo-SnowballTarget\" \\\n    --commit-message=\"Unit 5 SnowballTarget\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T21:14:53.792152Z","iopub.execute_input":"2026-02-24T21:14:53.792752Z","iopub.status.idle":"2026-02-24T21:14:58.765537Z","shell.execute_reply.started":"2026-02-24T21:14:53.792717Z","shell.execute_reply":"2026-02-24T21:14:58.764652Z"}},"outputs":[{"name":"stdout","text":"[INFO] This function will create a model card and upload your SnowballTarget1 into HuggingFace Hub. This is a work in progress: If you encounter a bug, please send open an issue\n[INFO] Pushing repo SnowballTarget1 to the Hugging Face Hub\nProcessing Files (0 / 0)      : |                  |  0.00B /  0.00B            \nNew Data Upload               : |                  |  0.00B /  0.00B            \u001b[A\n\n  ...owballTarget-1000696.onnx:   2%|‚ñé             | 13.6kB /  651kB            \u001b[A\u001b[A\n\n\n  ...SnowballTarget-1000696.pt:   2%|‚ñé             | 80.7kB / 3.85MB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...nowballTarget-399968.onnx:   2%|‚ñé             | 13.6kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  .../SnowballTarget-399968.pt:   2%|‚ñé             | 80.7kB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...nowballTarget-599976.onnx:   2%|‚ñé             | 13.6kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  .../SnowballTarget-599976.pt:   2%|‚ñé             | 80.7kB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...nowballTarget-799984.onnx:   2%|‚ñé             | 13.6kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  .../SnowballTarget-799984.pt:   2%|‚ñé             | 80.7kB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...nowballTarget-999992.onnx:   2%|‚ñé             | 13.6kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n  .../SnowballTarget-999992.pt:   2%|‚ñé             | 80.7kB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n  ...owballTarget-1000696.onnx:   2%|‚ñé             | 13.6kB /  651kB            \u001b[A\u001b[A\n\n\n  ...SnowballTarget-1000696.pt:   2%|‚ñé             | 80.7kB / 3.85MB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...nowballTarget-399968.onnx:   2%|‚ñé             | 13.6kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  .../SnowballTarget-399968.pt:   2%|‚ñé             | 80.7kB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...nowballTarget-599976.onnx:   2%|‚ñé             | 13.6kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  .../SnowballTarget-599976.pt:   2%|‚ñé             | 80.7kB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...nowballTarget-799984.onnx:   2%|‚ñé             | 13.6kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  .../SnowballTarget-799984.pt:   2%|‚ñé             | 80.7kB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...nowballTarget-999992.onnx:   2%|‚ñé             | 13.6kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nProcessing Files (0 / 16)     :   2%|‚ñé             |  568kB / 27.1MB, 2.84MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nNew Data Upload               :   2%|‚ñé             |  568kB / 27.1MB, 2.84MB/s  \u001b[A\n\n  ...owballTarget-1000696.onnx:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        |  259kB /  651kB            \u001b[A\u001b[A\n\n\n  ...SnowballTarget-1000696.pt:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 1.53MB / 3.85MB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...nowballTarget-399968.onnx:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        |  259kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  .../SnowballTarget-399968.pt:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 1.53MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...nowballTarget-599976.onnx:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        |  259kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  .../SnowballTarget-599976.pt:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 1.53MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...nowballTarget-799984.onnx:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        |  259kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  .../SnowballTarget-799984.pt:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 1.53MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...nowballTarget-999992.onnx:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        |  259kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nProcessing Files (0 / 16)     :  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 10.8MB / 27.1MB, 27.0MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nNew Data Upload               :  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 10.8MB / 27.1MB, 27.0MB/s  \u001b[A\n\n  ...owballTarget-1000696.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\n\n\n  ...SnowballTarget-1000696.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3.79MB / 3.85MB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...nowballTarget-399968.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  .../SnowballTarget-399968.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3.79MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...nowballTarget-599976.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  .../SnowballTarget-599976.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3.79MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...nowballTarget-799984.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  .../SnowballTarget-799984.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3.79MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...nowballTarget-999992.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nProcessing Files (0 / 16)     :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 26.7MB / 27.1MB, 44.5MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nNew Data Upload               :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 26.7MB / 27.1MB, 44.5MB/s  \u001b[A\n\n  ...owballTarget-1000696.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\n\n\n  ...SnowballTarget-1000696.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3.79MB / 3.85MB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...nowballTarget-399968.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  .../SnowballTarget-399968.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3.79MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...nowballTarget-599976.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  .../SnowballTarget-599976.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3.79MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...nowballTarget-799984.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  .../SnowballTarget-799984.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3.79MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...nowballTarget-999992.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n  [+ 6 files]                 :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8.33MB / 8.45MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n  ...owballTarget-1000696.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\n\n\n  ...SnowballTarget-1000696.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3.79MB / 3.85MB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...nowballTarget-399968.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  .../SnowballTarget-399968.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3.79MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...nowballTarget-599976.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  .../SnowballTarget-599976.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3.79MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...nowballTarget-799984.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  .../SnowballTarget-799984.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3.79MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...nowballTarget-999992.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n  [+ 6 files]                 :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8.33MB / 8.45MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n  ...owballTarget-1000696.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\n\n\n  ...SnowballTarget-1000696.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3.79MB / 3.85MB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...nowballTarget-399968.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  .../SnowballTarget-399968.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3.79MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...nowballTarget-599976.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  .../SnowballTarget-599976.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3.79MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...nowballTarget-799984.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  .../SnowballTarget-799984.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 3.79MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...nowballTarget-999992.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  641kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n  [+ 6 files]                 :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8.33MB / 8.45MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n  ...owballTarget-1000696.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  651kB /  651kB            \u001b[A\u001b[A\n\n\n  ...SnowballTarget-1000696.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.85MB / 3.85MB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...nowballTarget-399968.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  651kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  .../SnowballTarget-399968.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.85MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...nowballTarget-599976.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  651kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  .../SnowballTarget-599976.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.85MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...nowballTarget-799984.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  651kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  .../SnowballTarget-799984.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.85MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...nowballTarget-999992.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  651kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nProcessing Files (16 / 16)    : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27.1MB / 27.1MB, 19.4MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nNew Data Upload               : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27.1MB / 27.1MB, 19.4MB/s  \u001b[A\n\n  ...nowballTarget-799984.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  651kB /  651kB            \u001b[A\u001b[A\n\n\n  .../SnowballTarget-799984.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.85MB / 3.85MB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...nowballTarget-999992.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  651kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  .../SnowballTarget-999992.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.85MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...wballTarget/checkpoint.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.85MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  ...64269.99d11e677bcf.1923.0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33.4kB / 33.4kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...64824.99d11e677bcf.2014.0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.17kB / 1.17kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  ...65162.99d11e677bcf.2086.0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.17kB / 1.17kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...65496.99d11e677bcf.2184.0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66.7kB / 66.7kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n  ...rget1/SnowballTarget.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  651kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n  ...nowballTarget-799984.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  651kB /  651kB            \u001b[A\u001b[A\n\n\n  .../SnowballTarget-799984.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.85MB / 3.85MB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...nowballTarget-999992.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  651kB /  651kB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  .../SnowballTarget-999992.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.85MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...wballTarget/checkpoint.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.85MB / 3.85MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  ...64269.99d11e677bcf.1923.0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33.4kB / 33.4kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...64824.99d11e677bcf.2014.0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.17kB / 1.17kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  ...65162.99d11e677bcf.2086.0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.17kB / 1.17kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...65496.99d11e677bcf.2184.0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66.7kB / 66.7kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nProcessing Files (16 / 16)    : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27.1MB / 27.1MB, 16.9MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nNew Data Upload               : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27.1MB / 27.1MB, 16.9MB/s  \n  ...nowballTarget-799984.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  651kB /  651kB            \n  .../SnowballTarget-799984.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.85MB / 3.85MB            \n  ...nowballTarget-999992.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  651kB /  651kB            \n  .../SnowballTarget-999992.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.85MB / 3.85MB            \n  ...wballTarget/checkpoint.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.85MB / 3.85MB            \n  ...64269.99d11e677bcf.1923.0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33.4kB / 33.4kB            \n  ...64824.99d11e677bcf.2014.0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.17kB / 1.17kB            \n  ...65162.99d11e677bcf.2086.0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.17kB / 1.17kB            \n  ...65496.99d11e677bcf.2184.0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 66.7kB / 66.7kB            \n  ...rget1/SnowballTarget.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  651kB /  651kB            \n[INFO] Your model is pushed to the hub. You can view your model here: https://huggingface.co/Chiz/ppo-SnowballTarget\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"### Push Pyramids\n\n**Edit `--repo-id` to use your HuggingFace username**","metadata":{}},{"cell_type":"code","source":"!/kaggle/working/mlagents-env/bin/mlagents-push-to-hf \\\n    --run-id=\"Pyramids1\" \\\n    --local-dir=\"./results/Pyramids1\" \\\n    --repo-id=\"Chiz/ppo-Pyramids\" \\\n    --commit-message=\"Unit 5 Pyramids with curiosity\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-24T22:27:25.149519Z","iopub.execute_input":"2026-02-24T22:27:25.150100Z","iopub.status.idle":"2026-02-24T22:27:28.670153Z","shell.execute_reply.started":"2026-02-24T22:27:25.150067Z","shell.execute_reply":"2026-02-24T22:27:28.669188Z"}},"outputs":[{"name":"stdout","text":"[INFO] This function will create a model card and upload your Pyramids1 into HuggingFace Hub. This is a work in progress: If you encounter a bug, please send open an issue\n[INFO] Pushing repo Pyramids1 to the Hugging Face Hub\nProcessing Files (0 / 0)      : |                  |  0.00B /  0.00B            \nNew Data Upload               : |                  |  0.00B /  0.00B            \u001b[A\n\n  ...ids/Pyramids-1199919.onnx:   2%|‚ñé             | 8.73kB /  451kB            \u001b[A\u001b[A\n\n\n  ...amids/Pyramids-1199919.pt:   2%|‚ñé             | 81.2kB / 4.19MB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...ids/Pyramids-1399964.onnx:   2%|‚ñé             | 8.73kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  ...amids/Pyramids-1399964.pt:   2%|‚ñé             | 81.2kB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...ids/Pyramids-1500031.onnx:   2%|‚ñé             | 8.73kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  ...amids/Pyramids-1500031.pt:   2%|‚ñé             | 81.2kB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...mids/Pyramids-799915.onnx:   2%|‚ñé             | 8.73kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  ...ramids/Pyramids-799915.pt:   2%|‚ñé             | 81.2kB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...mids/Pyramids-999967.onnx:   2%|‚ñé             | 8.73kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n  ...ramids/Pyramids-999967.pt:   2%|‚ñé             | 81.2kB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n  ...ids/Pyramids-1199919.onnx:   2%|‚ñé             | 8.73kB /  451kB            \u001b[A\u001b[A\n\n\n  ...amids/Pyramids-1199919.pt:   2%|‚ñé             | 81.2kB / 4.19MB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...ids/Pyramids-1399964.onnx:   2%|‚ñé             | 8.73kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  ...amids/Pyramids-1399964.pt:   2%|‚ñé             | 81.2kB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...ids/Pyramids-1500031.onnx:   2%|‚ñé             | 8.73kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  ...amids/Pyramids-1500031.pt:   2%|‚ñé             | 81.2kB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...mids/Pyramids-799915.onnx:   2%|‚ñé             | 8.73kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  ...ramids/Pyramids-799915.pt:   2%|‚ñé             | 81.2kB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...mids/Pyramids-999967.onnx:   2%|‚ñé             | 8.73kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nProcessing Files (0 / 13)     :   2%|‚ñé             |  563kB / 29.1MB, 2.88MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nNew Data Upload               :   2%|‚ñé             |  563kB / 29.1MB, 2.88MB/s  \u001b[A\n\n  ...ids/Pyramids-1199919.onnx:  35%|‚ñà‚ñà‚ñà‚ñà‚ñâ         |  157kB /  451kB            \u001b[A\u001b[A\n\n\n  ...amids/Pyramids-1199919.pt:  35%|‚ñà‚ñà‚ñà‚ñà‚ñâ         | 1.46MB / 4.19MB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...ids/Pyramids-1399964.onnx:  35%|‚ñà‚ñà‚ñà‚ñà‚ñâ         |  157kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  ...amids/Pyramids-1399964.pt:  35%|‚ñà‚ñà‚ñà‚ñà‚ñâ         | 1.46MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...ids/Pyramids-1500031.onnx:  35%|‚ñà‚ñà‚ñà‚ñà‚ñâ         |  157kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  ...amids/Pyramids-1500031.pt:  35%|‚ñà‚ñà‚ñà‚ñà‚ñâ         | 1.46MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...mids/Pyramids-799915.onnx:  35%|‚ñà‚ñà‚ñà‚ñà‚ñâ         |  157kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  ...ramids/Pyramids-799915.pt:  35%|‚ñà‚ñà‚ñà‚ñà‚ñâ         | 1.46MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...mids/Pyramids-999967.onnx:  35%|‚ñà‚ñà‚ñà‚ñà‚ñâ         |  157kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nProcessing Files (0 / 13)     :  35%|‚ñà‚ñà‚ñà‚ñà‚ñâ         | 10.1MB / 29.1MB, 25.6MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nNew Data Upload               :  35%|‚ñà‚ñà‚ñà‚ñà‚ñâ         | 10.1MB / 29.1MB, 25.6MB/s  \u001b[A\n\n  ...ids/Pyramids-1199919.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  445kB /  451kB            \u001b[A\u001b[A\n\n\n  ...amids/Pyramids-1199919.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 4.14MB / 4.19MB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...ids/Pyramids-1399964.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  445kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  ...amids/Pyramids-1399964.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 4.14MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...ids/Pyramids-1500031.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  445kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  ...amids/Pyramids-1500031.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 4.14MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...mids/Pyramids-799915.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  445kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  ...ramids/Pyramids-799915.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 4.14MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...mids/Pyramids-999967.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  445kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nProcessing Files (0 / 13)     :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 28.7MB / 29.1MB, 48.2MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nNew Data Upload               :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 28.7MB / 29.1MB, 48.2MB/s  \u001b[A\n\n  ...ids/Pyramids-1199919.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  445kB /  451kB            \u001b[A\u001b[A\n\n\n  ...amids/Pyramids-1199919.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 4.14MB / 4.19MB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...ids/Pyramids-1399964.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  445kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  ...amids/Pyramids-1399964.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 4.14MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...ids/Pyramids-1500031.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  445kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  ...amids/Pyramids-1500031.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 4.14MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...mids/Pyramids-799915.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  445kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  ...ramids/Pyramids-799915.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 4.14MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...mids/Pyramids-999967.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  445kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n  [+ 3 files]                 :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 9.94MB / 10.1MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n  ...ids/Pyramids-1199919.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  445kB /  451kB            \u001b[A\u001b[A\n\n\n  ...amids/Pyramids-1199919.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 4.14MB / 4.19MB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...ids/Pyramids-1399964.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  445kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  ...amids/Pyramids-1399964.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 4.14MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...ids/Pyramids-1500031.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  445kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  ...amids/Pyramids-1500031.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 4.14MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...mids/Pyramids-799915.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  445kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  ...ramids/Pyramids-799915.pt:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 4.14MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...mids/Pyramids-999967.onnx:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä|  445kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n  [+ 3 files]                 :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 9.94MB / 10.1MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n  ...ids/Pyramids-1199919.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  451kB /  451kB            \u001b[A\u001b[A\n\n\n  ...amids/Pyramids-1199919.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...ids/Pyramids-1399964.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  451kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  ...amids/Pyramids-1399964.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...ids/Pyramids-1500031.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  451kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  ...amids/Pyramids-1500031.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...mids/Pyramids-799915.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  451kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  ...ramids/Pyramids-799915.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...mids/Pyramids-999967.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  451kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nProcessing Files (13 / 13)    : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29.1MB / 29.1MB, 24.3MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nNew Data Upload               : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29.1MB / 29.1MB, 24.3MB/s  \u001b[A\n\n  ...amids/Pyramids-1399964.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \u001b[A\u001b[A\n\n\n  ...ids/Pyramids-1500031.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  451kB /  451kB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...amids/Pyramids-1500031.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  ...mids/Pyramids-799915.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  451kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...ramids/Pyramids-799915.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  ...mids/Pyramids-999967.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  451kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...ramids/Pyramids-999967.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  ...s1/Pyramids/checkpoint.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...68356.99d11e677bcf.2389.0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.22MB / 1.22MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n  ...s/Pyramids1/Pyramids.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  451kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n  ...amids/Pyramids-1399964.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \u001b[A\u001b[A\n\n\n  ...ids/Pyramids-1500031.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  451kB /  451kB            \u001b[A\u001b[A\u001b[A\n\n\n\n  ...amids/Pyramids-1500031.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n  ...mids/Pyramids-799915.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  451kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n  ...ramids/Pyramids-799915.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n  ...mids/Pyramids-999967.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  451kB /  451kB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n  ...ramids/Pyramids-999967.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n  ...s1/Pyramids/checkpoint.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n  ...68356.99d11e677bcf.2389.0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.22MB / 1.22MB            \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\nProcessing Files (13 / 13)    : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29.1MB / 29.1MB, 20.8MB/s  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nNew Data Upload               : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29.1MB / 29.1MB, 20.8MB/s  \n  ...amids/Pyramids-1399964.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \n  ...ids/Pyramids-1500031.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  451kB /  451kB            \n  ...amids/Pyramids-1500031.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \n  ...mids/Pyramids-799915.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  451kB /  451kB            \n  ...ramids/Pyramids-799915.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \n  ...mids/Pyramids-999967.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  451kB /  451kB            \n  ...ramids/Pyramids-999967.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \n  ...s1/Pyramids/checkpoint.pt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.19MB / 4.19MB            \n  ...68356.99d11e677bcf.2389.0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.22MB / 1.22MB            \n  ...s/Pyramids1/Pyramids.onnx: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  451kB /  451kB            \n[INFO] Your model is pushed to the hub. You can view your model here: https://huggingface.co/Chiz/ppo-Pyramids\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"## Congrats on finishing Unit 5! üéâ\n\nYou can now play with your agents in the browser:\n\n- SnowballTarget: https://huggingface.co/spaces/ThomasSimonini/SnowballTarget\n- Pyramids: https://huggingface.co/spaces/unity/ML-Agents-Pyramids\n\nJust select your model from the dropdown!\n\n## Keep Learning, Stay Awesome ü§ó","metadata":{}}]}